{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Examples\n",
    "\n",
    "Here we give numerous example analysis of GWAS data with `MendelIHT.jl`. For exact function input/output descriptions, see the manuel's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.6.0\n",
      "Commit f9720dc2eb (2021-03-24 12:55 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin19.6.0)\n",
      "  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 8\n"
     ]
    }
   ],
   "source": [
    "# machine information for reproducibility\n",
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(1111)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load necessary packages for running all examples below\n",
    "using MendelIHT\n",
    "using SnpArrays\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using GLM\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using BenchmarkTools\n",
    "\n",
    "BLAS.set_num_threads(1) # prevent over subscription with multithreading & BLAS\n",
    "Random.seed!(1111)      # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MendelIHT.jl\n",
    "\n",
    "Users are exposed to 2 levels of interface:\n",
    "+ Wrapper functions [iht()](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.iht) and [cross_validate()](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.cross_validate). These functions are simple scripts that import data, runs IHT, and writes result to output automatically. Since they are very simplistic, they might fail for whatever reason (please file an issue on GitHub). If so, please use:\n",
    "+ Core functions [fit_iht()](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.fit_iht) and [cv_iht()](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.cv_iht). Input arguments for these functions must be first imported into Julia by the user manually.\n",
    "\n",
    "Below we use numerous examples to illustrate how to use these functions separately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel computing\n",
    "\n",
    "\n",
    "To exploit `MendelIHT.jl`'s parallel processing, [start Julia with multiple threads](https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads). Two levels of shared-memory parallelism is supported.\n",
    "+ (genotype-matrix)-(vector or matrix) multiplication\n",
    "+ cross validation\n",
    "\n",
    "**Note**: If one is running IHT on `Matrix{Float64}`, BLAS should NOT run with multiple threads (execute `BLAS.set_num_threads(1)` before running IHT). This prevents [oversubscription](https://ieeexplore.ieee.org/document/5470434). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads() # show number of threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: GWAS with PLINK/BGEN/VCF files\n",
    "\n",
    "In this example, our data are stored in binary PLINK files:\n",
    "\n",
    "+ `normal.bed`\n",
    "+ `normal.bim`\n",
    "+ `normal.fam`\n",
    "\n",
    "which contains simulated (Gaussian) phenotypes for $n=1000$ samples and $p=10,000$ SNPs. There are $8$ causal variants and 2 causal non-genetic covariates (intercept and sex). \n",
    "\n",
    "These data are present under `MendelIHT/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd() = \"/Users/biona001/.julia/dev/MendelIHT/data\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23-element Vector{String}:\n",
       " \".DS_Store\"\n",
       " \"README.md\"\n",
       " \"covariates.txt\"\n",
       " \"cviht.summary.txt\"\n",
       " \"iht.beta.txt\"\n",
       " \"iht.cov.txt\"\n",
       " \"iht.summary.txt\"\n",
       " \"multivariate.bed\"\n",
       " \"multivariate.bim\"\n",
       " \"multivariate.fam\"\n",
       " \"multivariate.phen\"\n",
       " \"multivariate.trait.cov\"\n",
       " \"normal.bed\"\n",
       " \"normal.bim\"\n",
       " \"normal.fam\"\n",
       " \"normal_true_beta.txt\"\n",
       " \"phenotypes.txt\"\n",
       " \"sim.bed\"\n",
       " \"sim.bim\"\n",
       " \"sim.covariates.txt\"\n",
       " \"sim.fam\"\n",
       " \"sim.phenotypes.txt\"\n",
       " \"simulate.jl\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory to where example data is located\n",
    "cd(normpath(MendelIHT.datadir()))\n",
    "\n",
    "# show working directory\n",
    "@show pwd() \n",
    "\n",
    "# show files in current directory\n",
    "readdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `covariates.txt` contains non-genetic covariates (intercept + sex), `normal.bed/bim/fam` are the PLINK files storing genetic covariates, `phenotypes.txt` are phenotypes for each sample, `normal_true_beta.txt` is the true statistical model used to generate the phenotypes, and `simulate.jl` is the script used to generate all the files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Run cross validation to determine best model size\n",
    "\n",
    "See the [cross_validate](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.cross_validate) function API. Here, \n",
    "+ We run 5 fold cross validation (default `q`) across k = 1, 2, ..., 20.\n",
    "+ Phenotypes are stored in the 6th column of `.fam` file\n",
    "+ Other covariates are stored separately (which includes a column of 1 as intercept). Here we cross validate $k = 1,2,...20$. \n",
    "\n",
    "Note the first run might take awhile because Julia needs to compile the code. See FAQ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****                   MendelIHT Version 1.4.1                  ****\n",
      "****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****\n",
      "****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****\n",
      "****                                                            ****\n",
      "****                 Please cite our paper!                     ****\n",
      "****         https://doi.org/10.1093/gigascience/giaa044        ****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCross validating...100%|████████████████████████████████| Time: 0:00:03\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crossvalidation Results:\n",
      "\tk\tMSE\n",
      "\t1\t743.1703938637883\n",
      "\t2\t550.1707865831861\n",
      "\t3\t426.4937801368892\n",
      "\t4\t336.20365731861745\n",
      "\t5\t296.0672451743466\n",
      "\t6\t233.02850102286234\n",
      "\t7\t197.94215895091278\n",
      "\t8\t199.6451087657394\n",
      "\t9\t201.54148479914127\n",
      "\t10\t207.96968107938025\n",
      "\t11\t212.9172082563968\n",
      "\t12\t215.32570044375092\n",
      "\t13\t220.99781565117684\n",
      "\t14\t220.78097392409862\n",
      "\t15\t224.33931887771\n",
      "\t16\t220.7001228820031\n",
      "\t17\t226.6527593460433\n",
      "\t18\t227.36164871842863\n",
      "\t19\t237.23200258515894\n",
      "\t20\t238.24759588500916\n",
      "\n",
      "Best k = 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mses = cross_validate(\"normal\", Normal, covariates=\"covariates.txt\", phenotypes=6, path=1:20,);\n",
    "\n",
    "# Alternative syntax\n",
    "# mses = cross_validate(\"normal\", Normal, covariates=\"covariates.txt\", phenotypes=6, path=[1, 5, 10, 15, 20]) # test k = 1, 5, 10, 15, 20\n",
    "# mses = cross_validate(\"normal\", Normal, covariates=\"covariates.txt\", phenotypes=\"phenotypes.txt\", path=1:20) # when phenotypes are stored separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not be alarmed if you get slightly different numbers, because cross validation breaks data into training/testing randomly. Set a seed by `Random.seed!(1234)` if you want reproducibility.\n",
    "\n",
    "!!! note\n",
    "\n",
    "    For VCF (`.vcf` or `.vcf.gz` and BGEN inputs, one simply add the file extensions to the wrapper functions. For instance, `cross_validate(\"normal.vcf.gz\", Normal`) for VCF and `mses = cross_validate(\"normal.bgen\", Normal)`. Note for BGEN, sample file name should be `normal.sample`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run IHT on best k\n",
    "\n",
    "See the [iht](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.iht) function API.\n",
    "\n",
    "According to cross validation, `k = 7` achieves the minimum MSE. Thus we run IHT on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****                   MendelIHT Version 1.4.1                  ****\n",
      "****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****\n",
      "****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****\n",
      "****                                                            ****\n",
      "****                 Please cite our paper!                     ****\n",
      "****         https://doi.org/10.1093/gigascience/giaa044        ****\n",
      "\n",
      "Running sparse linear regression\n",
      "Number of threads = 8\n",
      "Link functin = IdentityLink()\n",
      "Sparsity parameter (k) = 7\n",
      "Prior weight scaling = off\n",
      "Doubly sparse projection = off\n",
      "Debias = off\n",
      "Max IHT iterations = 200\n",
      "Converging when tol < 0.0001 and iteration ≥ 5:\n",
      "\n",
      "Iteration 1: loglikelihood = -1403.6085154464329, backtracks = 0, tol = 0.8141937613701785\n",
      "Iteration 2: loglikelihood = -1397.922430744325, backtracks = 0, tol = 0.017959863148623176\n",
      "Iteration 3: loglikelihood = -1397.8812223841496, backtracks = 0, tol = 0.001989846075839033\n",
      "Iteration 4: loglikelihood = -1397.8807476657355, backtracks = 0, tol = 0.00016446741159857614\n",
      "Iteration 5: loglikelihood = -1397.8807416751808, backtracks = 0, tol = 2.0482155566893502e-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 7 nonzero SNP predictors and 2 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.028419017791748047\n",
       "Final loglikelihood:    -1397.8807416751808\n",
       "SNP PVE:                0.8343751445053728\n",
       "Iterations:             5\n",
       "\n",
       "Selected genetic predictors:\n",
       "\u001b[1m7×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │     3137     0.424376\n",
       "   2 │     4246     0.52343\n",
       "   3 │     4717     0.922857\n",
       "   4 │     6290    -0.677832\n",
       "   5 │     7755    -0.542983\n",
       "   6 │     8375    -0.792813\n",
       "   7 │     9415    -2.17998\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "\u001b[1m2×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │        1     1.65223\n",
       "   2 │        2     0.749865"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = iht(\"normal\", 7, Normal, covariates=\"covariates.txt\", phenotypes=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convergence criteria can be tuned by keywords `tol` and `min_iter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Examine results\n",
    "\n",
    "IHT picked 7 SNPs. The `Position` argument corresponds to the order in which the SNP appeared in the PLINK file, and the `Estimated_β` argument is the estimated effect size for the selected SNPs. To extract more information (for instance to extract `rs` IDs), we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_snps = 7×6 DataFrame\n",
      " Row │ chromosome  snpid    genetic_distance  position  allele1  allele2\n",
      "     │ String      String   Float64           Int64     String   String\n",
      "─────┼───────────────────────────────────────────────────────────────────\n",
      "   1 │ 1           snp3137               0.0         1  1        2\n",
      "   2 │ 1           snp4246               0.0         1  1        2\n",
      "   3 │ 1           snp4717               0.0         1  1        2\n",
      "   4 │ 1           snp6290               0.0         1  1        2\n",
      "   5 │ 1           snp7755               0.0         1  1        2\n",
      "   6 │ 1           snp8375               0.0         1  1        2\n",
      "   7 │ 1           snp9415               0.0         1  1        2\n"
     ]
    }
   ],
   "source": [
    "snpdata = SnpData(\"normal\")                   # import PLINK information\n",
    "snps_idx = findall(!iszero, result.beta)      # indices of SNPs selected by IHT\n",
    "selected_snps = snpdata.snp_info[snps_idx, :] # see which SNPs are selected\n",
    "@show selected_snps;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above displays the SNP information for the selected SNPs. Because there's only 7 causal SNPs, we found all of them. The 2 non-genetic covariates represented intercept and sex, with true effect size 1.5 and 1.0. Since data is simulated, the fields `chromosome`, `snpid`, `genetic_distance`, `position`, `allele1`, and `allele2` are fake. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: How to simulate data\n",
    "\n",
    "Here we demonstrate how to use `MendelIHT.jl` and [SnpArrays.jl](https://github.com/OpenMendel/SnpArrays.jl) to simulate data, allowing you to design your own genetic studies. Note:\n",
    "+ For more complex simulation, please use the module [TraitSimulations.jl](https://github.com/OpenMendel/TraitSimulation.jl).  \n",
    "+ All linear algebra routines involving PLINK files are handled by [SnpArrays.jl](https://github.com/OpenMendel/SnpArrays.jl). \n",
    "\n",
    "First we simulate an example PLINK trio (`.bim`, `.bed`, `.fam`) and non-genetic covariates, then we illustrate how to import them. For simplicity, let us simulated indepent SNPs with binary phenotypes. Explicitly, our model is:\n",
    "\n",
    "$$y_i \\sim \\rm Bernoulli(\\mathbf{x}_i^T\\boldsymbol\\beta)$$\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 1)$$\n",
    "$$\\beta_{\\rm intercept} = 1$$\n",
    "$$\\beta_{\\rm sex} = 1.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1000            # number of samples\n",
    "p = 10000           # number of SNPs\n",
    "k = 10              # 10 causal SNPs\n",
    "d = Bernoulli       # Binary (continuous) phenotypes\n",
    "l = LogitLink()     # canonical link function\n",
    "\n",
    "# set random seed\n",
    "Random.seed!(0)\n",
    "\n",
    "# simulate `sim.bed` file with no missing data\n",
    "x = simulate_random_snparray(\"sim.bed\", n, p)\n",
    "xla = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true, impute=true) \n",
    "\n",
    "# 2 nongenetic covariate: first column is the intercept, second column is sex: 0 = male 1 = female\n",
    "z = ones(n, 2) \n",
    "z[:, 2] .= rand(0:1, n)\n",
    "standardize!(@view(z[:, 2:end])) \n",
    "\n",
    "# randomly set genetic predictors where causal βᵢ ~ N(0, 1)\n",
    "true_b = zeros(p) \n",
    "true_b[1:k] = randn(k)\n",
    "shuffle!(true_b)\n",
    "\n",
    "# find correct position of genetic predictors\n",
    "correct_position = findall(!iszero, true_b)\n",
    "\n",
    "# define effect size of non-genetic predictors: intercept & sex\n",
    "true_c = [1.0; 1.5] \n",
    "\n",
    "# simulate phenotype using genetic and nongenetic predictors\n",
    "prob = GLM.linkinv.(l, xla * true_b .+ z * true_c) # note genotype-vector multiplication is done with `xla`\n",
    "y = [rand(d(i)) for i in prob]\n",
    "y = Float64.(y); # turn y into floating point numbers\n",
    "\n",
    "# create `sim.bim` and `sim.bam` files using phenotype\n",
    "make_bim_fam_files(x, y, \"sim\")\n",
    "\n",
    "#save covariates and phenotypes (without header)\n",
    "writedlm(\"sim.covariates.txt\", z, ',')\n",
    "writedlm(\"sim.phenotypes.txt\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "\n",
    "    Please **standardize** (or at least center) your non-genetic covariates. If you use our `iht()` or `cross_validation()` functions, standardization is automatic. For genotype matrix, `SnpLinAlg` efficiently achieves this standardization. For non-genetic covariates, please use the built-in function `standardize!`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Logistic/Poisson/Negative-binomial GWAS\n",
    "\n",
    "In Example 2, we simulated binary phenotypes, genotypes, non-genetic covariates, and we know true $k = 10$. Let's try running a logistic regression (i.e. phenotype follows the Bernoulli distribution) on this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****                   MendelIHT Version 1.4.1                  ****\n",
      "****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****\n",
      "****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****\n",
      "****                                                            ****\n",
      "****                 Please cite our paper!                     ****\n",
      "****         https://doi.org/10.1093/gigascience/giaa044        ****\n",
      "\n",
      "Running sparse logistic regression\n",
      "Number of threads = 8\n",
      "Link functin = LogitLink()\n",
      "Sparsity parameter (k) = 10\n",
      "Prior weight scaling = off\n",
      "Doubly sparse projection = off\n",
      "Debias = off\n",
      "Max IHT iterations = 200\n",
      "Converging when tol < 0.0001 and iteration ≥ 5:\n",
      "\n",
      "Iteration 1: loglikelihood = -410.3429870797691, backtracks = 0, tol = 0.634130944297718\n",
      "Iteration 2: loglikelihood = -355.96269238167594, backtracks = 0, tol = 0.23373909459507045\n",
      "Iteration 3: loglikelihood = -335.19699443343046, backtracks = 0, tol = 0.1883878956755205\n",
      "Iteration 4: loglikelihood = -326.72483097632033, backtracks = 1, tol = 0.11662243126023769\n",
      "Iteration 5: loglikelihood = -323.42465587337426, backtracks = 1, tol = 0.1420748329251797\n",
      "Iteration 6: loglikelihood = -321.93583078185304, backtracks = 1, tol = 0.026234221625522528\n",
      "Iteration 7: loglikelihood = -321.14096662573917, backtracks = 2, tol = 0.01403839948881654\n",
      "Iteration 8: loglikelihood = -320.42084987563976, backtracks = 2, tol = 0.13238847469548456\n",
      "Iteration 9: loglikelihood = -319.96246645074956, backtracks = 1, tol = 0.011420657379532422\n",
      "Iteration 10: loglikelihood = -319.70632025148103, backtracks = 2, tol = 0.00906035620905566\n",
      "Iteration 11: loglikelihood = -319.5850116168617, backtracks = 3, tol = 0.00526542665002791\n",
      "Iteration 12: loglikelihood = -319.48907690537277, backtracks = 3, tol = 0.004636845354902531\n",
      "Iteration 13: loglikelihood = -319.4139596352546, backtracks = 3, tol = 0.00408655714336715\n",
      "Iteration 14: loglikelihood = -319.35538714433477, backtracks = 3, tol = 0.003602878389767637\n",
      "Iteration 15: loglikelihood = -319.3098337852715, backtracks = 3, tol = 0.0031763270937268033\n",
      "Iteration 16: loglikelihood = -319.2744765345821, backtracks = 3, tol = 0.0027994055509261194\n",
      "Iteration 17: loglikelihood = -319.2470792984031, backtracks = 3, tol = 0.002466034977718209\n",
      "Iteration 18: loglikelihood = -319.22588090965274, backtracks = 3, tol = 0.002171162642890488\n",
      "Iteration 19: loglikelihood = -319.2094997186901, backtracks = 3, tol = 0.001910458491633558\n",
      "Iteration 20: loglikelihood = -319.196855221667, backtracks = 3, tol = 0.0016801251066566392\n",
      "Iteration 21: loglikelihood = -319.1871046680043, backtracks = 3, tol = 0.0014767880705742493\n",
      "Iteration 22: loglikelihood = -319.1795922518739, backtracks = 3, tol = 0.0012974307079079153\n",
      "Iteration 23: loglikelihood = -319.17380866099757, backtracks = 3, tol = 0.0011393509372972647\n",
      "Iteration 24: loglikelihood = -319.16935904315795, backtracks = 3, tol = 0.0010001288849418076\n",
      "Iteration 25: loglikelihood = -319.1659377513872, backtracks = 3, tol = 0.0008775999638190499\n",
      "Iteration 26: loglikelihood = -319.16330850846356, backtracks = 3, tol = 0.0007698310622097819\n",
      "Iteration 27: loglikelihood = -319.16128887828387, backtracks = 3, tol = 0.0006750988244862079\n",
      "Iteration 28: loglikelihood = -319.1597381430372, backtracks = 3, tol = 0.0005918695947373657\n",
      "Iteration 29: loglikelihood = -319.1585478622643, backtracks = 3, tol = 0.0005187808423979859\n",
      "Iteration 30: loglikelihood = -319.1576345361046, backtracks = 3, tol = 0.0004546239877395596\n",
      "Iteration 31: loglikelihood = -319.15693391434667, backtracks = 3, tol = 0.0003983285784910115\n",
      "Iteration 32: loglikelihood = -319.1563965892339, backtracks = 3, tol = 0.000348947774612114\n",
      "Iteration 33: loglikelihood = -319.15598458731, backtracks = 3, tol = 0.00030564509321785363\n",
      "Iteration 34: loglikelihood = -319.15566873708605, backtracks = 3, tol = 0.0002676823575045028\n",
      "Iteration 35: loglikelihood = -319.15542663816296, backtracks = 3, tol = 0.00023440878567259604\n",
      "Iteration 36: loglikelihood = -319.15524109586636, backtracks = 3, tol = 0.00020525114972271962\n",
      "Iteration 37: loglikelihood = -319.1550989157, backtracks = 3, tol = 0.00017970493004996346\n",
      "Iteration 38: loglikelihood = -319.15498997558825, backtracks = 3, tol = 0.00015732638998333223\n",
      "Iteration 39: loglikelihood = -319.1549065123602, backtracks = 3, tol = 0.00013772549451164306\n",
      "Iteration 40: loglikelihood = -319.1548425732977, backtracks = 3, tol = 0.00012055959910162006\n",
      "Iteration 41: loglikelihood = -319.15479359478843, backtracks = 3, tol = 0.00010552783734578194\n",
      "Iteration 42: loglikelihood = -319.154756078745, backtracks = 3, tol = 9.236613986923397e-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 10 nonzero SNP predictors and 2 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.41863417625427246\n",
       "Final loglikelihood:    -319.154756078745\n",
       "SNP PVE:                0.5719420735919515\n",
       "Iterations:             42\n",
       "\n",
       "Selected genetic predictors:\n",
       "\u001b[1m10×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │      520     0.400331\n",
       "   2 │      715    -0.663321\n",
       "   3 │      778    -0.497369\n",
       "   4 │     1357     1.25802\n",
       "   5 │     3266    -0.543574\n",
       "   6 │     5492    -0.879088\n",
       "   7 │     5800     0.595109\n",
       "   8 │     6049    -0.488677\n",
       "   9 │     6301    -2.22547\n",
       "  10 │     7059     0.797472\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "\u001b[1m2×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │        1      1.06077\n",
       "   2 │        2      1.41398"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = iht(\"sim\", 10, Bernoulli, covariates=\"sim.covariates.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data is simulated, we can compare IHT's estimated effect size with the truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2 Matrix{Float64}:\n",
       " -0.787272  -0.663321\n",
       " -0.456783  -0.497369\n",
       "  1.12735    1.25802\n",
       " -0.276592  -0.543574\n",
       "  0.185925   0.0\n",
       " -0.891023  -0.879088\n",
       "  0.498309   0.595109\n",
       " -2.15515   -2.22547\n",
       "  0.166931   0.0\n",
       "  0.82265    0.797472"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[true_b[correct_position] result.beta[correct_position]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "+ The 1st column are the true beta values, and the 2nd column is the estimated values. \n",
    "+ IHT found 8/10 genetic predictors, and estimates are reasonably close to truth. \n",
    "+ IHT missed SNPs with small effect size. With increased sample size, these small effects can be detected.\n",
    "+ The estimated non-genetic effect size is also very close to the truth (1.0 and 1.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove simulated data once they are no longer needed\n",
    "rm(\"sim.bed\", force=true)\n",
    "rm(\"sim.bim\", force=true)\n",
    "rm(\"sim.fam\", force=true)\n",
    "rm(\"sim.covariates.txt\", force=true)\n",
    "rm(\"sim.phenotypes.txt\", force=true)\n",
    "rm(\"iht.beta.txt\", force=true)\n",
    "rm(\"iht.summary.txt\", force=true)\n",
    "rm(\"cviht.summary.txt\", force=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Running IHT on general matrices\n",
    "\n",
    "To run IHT on numeric matrices, one must call [fit_iht](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.fit_iht) and [cv_iht](https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.cv_iht) directly. These functions are designed to work on `AbstractArray{T, 2}` type where `T` is a `Float64` or `Float32`. \n",
    "\n",
    "Note the vector of 1s (intercept) shouldn't be included in the design matrix itself, as it will be automatically included.\n",
    "\n",
    "First we simulate some count response using the model:\n",
    "\n",
    "$$y_i \\sim \\rm Poisson(\\mathbf{x}_i^T \\boldsymbol\\beta)$$\n",
    "$$x_{ij} \\sim \\rm Normal(0, 1)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 0.3)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1000             # number of samples\n",
    "p = 10000            # number of SNPs\n",
    "k = 10               # 9 causal predictors + intercept\n",
    "d = Poisson          # Response distribution (count data)\n",
    "l = LogLink()        # canonical link\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2020)\n",
    "\n",
    "# simulate design matrix\n",
    "x = randn(n, p)\n",
    "\n",
    "# simulate response, true model b, and the correct non-0 positions of b\n",
    "true_b = zeros(p)\n",
    "true_b[1:k] .= rand(Normal(0, 0.5), k)\n",
    "shuffle!(true_b)\n",
    "intercept = 1.0\n",
    "correct_position = findall(!iszero, true_b)\n",
    "prob = GLM.linkinv.(l, intercept .+ x * true_b)\n",
    "clamp!(prob, -20, 20) # prevents overflow\n",
    "y = [rand(d(i)) for i in prob]\n",
    "y = Float64.(y); # convert phenotypes to double precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the response $y$, design matrix $x$. Let's run IHT and compare with truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****                   MendelIHT Version 1.4.1                  ****\n",
      "****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****\n",
      "****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****\n",
      "****                                                            ****\n",
      "****                 Please cite our paper!                     ****\n",
      "****         https://doi.org/10.1093/gigascience/giaa044        ****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCross validating...100%|████████████████████████████████| Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crossvalidation Results:\n",
      "\tk\tMSE\n",
      "\t1\t706.7023831995504\n",
      "\t2\t563.0550969636545\n",
      "\t3\t475.3126336967697\n",
      "\t4\t448.33305489844025\n",
      "\t5\t473.3927061149886\n",
      "\t6\t475.9412876637349\n",
      "\t7\t511.93220168171354\n",
      "\t8\t536.4191695297267\n",
      "\t9\t543.6710949911146\n",
      "\t10\t546.9984660275643\n",
      "\t11\t566.3240592279342\n",
      "\t12\t582.0306543995698\n",
      "\t13\t572.2797797481932\n",
      "\t14\t555.79078283183\n",
      "\t15\t604.8674191407598\n",
      "\t16\t596.6516289181405\n",
      "\t17\t620.9209742466778\n",
      "\t18\t617.8251652635175\n",
      "\t19\t668.4065630346416\n",
      "\t20\t620.4559701381145\n",
      "\n",
      "Best k = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first run cross validation \n",
    "mses = cv_iht(y, x, path=1:20, d=Poisson(), l=LogLink());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run IHT on the full dataset using the best k (achieved at k = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****                   MendelIHT Version 1.4.1                  ****\n",
      "****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****\n",
      "****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****\n",
      "****                                                            ****\n",
      "****                 Please cite our paper!                     ****\n",
      "****         https://doi.org/10.1093/gigascience/giaa044        ****\n",
      "\n",
      "Running sparse Poisson regression\n",
      "Number of threads = 8\n",
      "Link functin = LogLink()\n",
      "Sparsity parameter (k) = 4\n",
      "Prior weight scaling = off\n",
      "Doubly sparse projection = off\n",
      "Debias = off\n",
      "Max IHT iterations = 200\n",
      "Converging when tol < 0.0001 and iteration ≥ 5:\n",
      "\n",
      "Iteration 1: loglikelihood = -2931.927168207526, backtracks = 0, tol = 0.3028304004126476\n",
      "Iteration 2: loglikelihood = -2463.976586409181, backtracks = 0, tol = 0.05258775986537314\n",
      "Iteration 3: loglikelihood = -2390.0609910861317, backtracks = 0, tol = 0.05578942533348056\n",
      "Iteration 4: loglikelihood = -2360.2573652460405, backtracks = 0, tol = 0.030501089537329825\n",
      "Iteration 5: loglikelihood = -2347.564682228364, backtracks = 0, tol = 0.021241566894705643\n",
      "Iteration 6: loglikelihood = -2341.213319235788, backtracks = 0, tol = 0.014911500576741359\n",
      "Iteration 7: loglikelihood = -2338.1595979203516, backtracks = 0, tol = 0.009977646130123972\n",
      "Iteration 8: loglikelihood = -2336.62260487827, backtracks = 0, tol = 0.007575531231741733\n",
      "Iteration 9: loglikelihood = -2335.880219053057, backtracks = 0, tol = 0.004805807684709317\n",
      "Iteration 10: loglikelihood = -2335.5141435762675, backtracks = 0, tol = 0.0037615233194204824\n",
      "Iteration 11: loglikelihood = -2335.3385905823416, backtracks = 0, tol = 0.002308369328965646\n",
      "Iteration 12: loglikelihood = -2335.253553769631, backtracks = 0, tol = 0.0018289326626755682\n",
      "Iteration 13: loglikelihood = -2335.213007797983, backtracks = 0, tol = 0.0011024772411982043\n",
      "Iteration 14: loglikelihood = -2335.193580900639, backtracks = 0, tol = 0.0008779579192619493\n",
      "Iteration 15: loglikelihood = -2335.1843486179923, backtracks = 0, tol = 0.0005244723959117778\n",
      "Iteration 16: loglikelihood = -2335.1799508662666, backtracks = 0, tol = 0.00041859562583677315\n",
      "Iteration 17: loglikelihood = -2335.177864471046, backtracks = 0, tol = 0.0002489580169555706\n",
      "Iteration 18: loglikelihood = -2335.1768735313717, backtracks = 0, tol = 0.0001989010930461795\n",
      "Iteration 19: loglikelihood = -2335.1764038008278, backtracks = 0, tol = 0.00011804464492615356\n",
      "Iteration 20: loglikelihood = -2335.176181018449, backtracks = 0, tol = 9.43540926080076e-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 4 nonzero SNP predictors and 1 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.11140608787536621\n",
       "Final loglikelihood:    -2335.176181018449\n",
       "SNP PVE:                0.09120222939725625\n",
       "Iterations:             20\n",
       "\n",
       "Selected genetic predictors:\n",
       "\u001b[1m4×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │       83    -0.809399\n",
       "   2 │      989     0.378437\n",
       "   3 │     4294    -0.274581\n",
       "   4 │     4459     0.16944\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "\u001b[1m1×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │        1      1.26924"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fit_iht(y, x, k=argmin(mses), d=Poisson(), l=LogLink())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2 Matrix{Float64}:\n",
       " -1.303      -0.809399\n",
       "  0.585809    0.378437\n",
       " -0.0700563   0.0\n",
       " -0.0901341   0.0\n",
       " -0.0620201   0.0\n",
       " -0.441452   -0.274581\n",
       "  0.271429    0.16944\n",
       " -0.164888    0.0\n",
       " -0.0790484   0.0\n",
       "  0.0829054   0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare IHT result with truth\n",
    "[true_b[correct_position] result.beta[correct_position]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many of the true $\\beta$ are small, we were only able to find 4 true signals (+ intercept). \n",
    "\n",
    "**Conclusion:** In this example, we ran IHT on count response with a general `Matrix{Float64}` design matrix. Since we used simulated data, we could compare IHT's estimates with the truth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Group IHT \n",
    "\n",
    "In this example, we show how to include group information to perform doubly sparse projections. Here the final model would contain at most $J = 5$ groups where each group contains limited number of (prespecified) SNPs. For simplicity, we assume the sparsity parameter $k$ is known. \n",
    "\n",
    "### Data simulation\n",
    "To illustrate the effect of group IHT, we generated correlated genotype matrix according to the procedure outlined in [our paper](https://www.biorxiv.org/content/biorxiv/early/2019/11/19/697755.full.pdf). In this example, each SNP belongs to 1 of 500 disjoint groups containing 20 SNPs each; $j = 5$ distinct groups are each assigned $1,2,...,5$ causal SNPs with effect sizes randomly chosen from $\\{−0.2,0.2\\}$. In all there 15 causal SNPs.  For grouped-IHT, we assume perfect group information. That is, the selected groups containing 1∼5 causative SNPs are assigned maximum within-group sparsity $\\lambda_g = 1,2,...,5$. The remaining groups are assigned $\\lambda_g = 1$ (i.e. only 1 active predictor are allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define problem size\n",
    "d = NegativeBinomial\n",
    "l = LogLink()\n",
    "n = 1000\n",
    "p = 10000\n",
    "block_size = 20                  #simulation parameter\n",
    "num_blocks = Int(p / block_size) #simulation parameter\n",
    "\n",
    "# set seed\n",
    "Random.seed!(1234)\n",
    "\n",
    "# assign group membership\n",
    "membership = collect(1:num_blocks)\n",
    "g = zeros(Int64, p)\n",
    "for i in 1:length(membership)\n",
    "    for j in 1:block_size\n",
    "        cur_row = block_size * (i - 1) + j\n",
    "        g[block_size*(i - 1) + j] = membership[i]\n",
    "    end\n",
    "end\n",
    "\n",
    "#simulate correlated snparray\n",
    "x = simulate_correlated_snparray(\"tmp.bed\", n, p)\n",
    "intercept = 0.5\n",
    "x_float = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, center=true, scale=true)\n",
    "\n",
    "#simulate true model, where 5 groups each with 1~5 snps contribute\n",
    "true_b = zeros(p)\n",
    "true_groups = randperm(num_blocks)[1:5]\n",
    "sort!(true_groups)\n",
    "within_group = [randperm(block_size)[1:1], randperm(block_size)[1:2], \n",
    "                randperm(block_size)[1:3], randperm(block_size)[1:4], \n",
    "                randperm(block_size)[1:5]]\n",
    "correct_position = zeros(Int64, 15)\n",
    "for i in 1:5\n",
    "    cur_group = block_size * (true_groups[i] - 1)\n",
    "    cur_group_snps = cur_group .+ within_group[i]\n",
    "    start, last = Int(i*(i-1)/2 + 1), Int(i*(i+1)/2)\n",
    "    correct_position[start:last] .= cur_group_snps\n",
    "end\n",
    "for i in 1:15\n",
    "    true_b[correct_position[i]] = rand(-1:2:1) * 0.2\n",
    "end\n",
    "sort!(correct_position)\n",
    "\n",
    "# simulate phenotype\n",
    "r = 10 #nuisance parameter\n",
    "μ = GLM.linkinv.(l, intercept .+ x_float * true_b)\n",
    "clamp!(μ, -20, 20)\n",
    "prob = 1 ./ (1 .+ μ ./ r)\n",
    "y = [rand(d(r, i)) for i in prob] #number of failures before r success occurs\n",
    "y = Float64.(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run IHT without groups\n",
    "ungrouped = fit_iht(y, x_float, k=15, d=NegativeBinomial(), l=LogLink(), verbose=false)\n",
    "\n",
    "#run doubly sparse (group) IHT by specifying maximum number of SNPs for each group (in order)\n",
    "max_group_snps = ones(Int, num_blocks)\n",
    "max_group_snps[true_groups] .= collect(1:5)\n",
    "variable_group = fit_iht(y, x_float, d=NegativeBinomial(), l=LogLink(), k=max_group_snps, J=5, group=g, verbose=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_model = 15×4 DataFrame\n",
      " Row │ position  correct_β  ungrouped_IHT_β  grouped_IHT_β\n",
      "     │ Int64     Float64    Float64          Float64\n",
      "─────┼─────────────────────────────────────────────────────\n",
      "   1 │      126        0.2         0.193695       0.179699\n",
      "   2 │     5999       -0.2        -0.238721      -0.221097\n",
      "   3 │     6000       -0.2        -0.139758      -0.145219\n",
      "   4 │     6344       -0.2        -0.210029      -0.204669\n",
      "   5 │     6359        0.2         0.212363       0.220925\n",
      "   6 │     6360       -0.2        -0.182878      -0.186936\n",
      "   7 │     7050       -0.2        -0.203551      -0.109019\n",
      "   8 │     7051       -0.2        -0.286369      -0.270932\n",
      "   9 │     7058       -0.2        -0.216709       0.0\n",
      "  10 │     7059        0.2         0.185836       0.0\n",
      "  11 │     7188        0.2         0.0            0.136334\n",
      "  12 │     7190       -0.2         0.0           -0.147534\n",
      "  13 │     7192        0.2         0.173384       0.173011\n",
      "  14 │     7195       -0.2        -0.233133      -0.225417\n",
      "  15 │     7198        0.2         0.0            0.131244\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check result\n",
    "correct_position = findall(!iszero, true_b)\n",
    "compare_model = DataFrame(\n",
    "    position = correct_position,\n",
    "    correct_β = true_b[correct_position],\n",
    "    ungrouped_IHT_β = ungrouped.beta[correct_position], \n",
    "    grouped_IHT_β = variable_group.beta[correct_position])\n",
    "@show compare_model\n",
    "println(\"\\n\")\n",
    "\n",
    "#clean up. Windows user must do this step manually (outside notebook/REPL)\n",
    "rm(\"tmp.bed\", force=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Grouped IHT found 1 extra SNP, but ungrouped IHT also recovered 2 SNPs that grouped IHT didn't find. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Linear Regression with prior weights\n",
    "\n",
    "In this example, we show how to include (predetermined) prior weights for each SNP. You can check out [our paper](https://www.biorxiv.org/content/biorxiv/early/2019/11/19/697755.full.pdf) for references of why/how to choose these weights. In this case, we mimic our paper and randomly set $10\\%$ of all SNPs to have a weight of $2.0$. Other predictors have weight of $1.0$. All causal SNPs have weights of $2.0$. Under this scenario, SNPs with weight $2.0$ is twice as likely to enter the model identified by IHT. \n",
    "\n",
    "Our model is simulated as:\n",
    "\n",
    "$$y_i \\sim \\mathbf{x}_i^T\\mathbf{\\beta} + \\epsilon_i$$\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "$$\\epsilon_i \\sim \\rm N(0, 1)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 0.25)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = Normal\n",
    "l = IdentityLink()\n",
    "n = 1000\n",
    "p = 10000\n",
    "k = 10\n",
    "\n",
    "#random seed\n",
    "Random.seed!(4)\n",
    "\n",
    "# construct snpmatrix, covariate files, and true model b\n",
    "x = simulate_random_snparray(\"tmp.bed\", n, p)\n",
    "X = convert(Matrix{Float64}, x, center=true, scale=true)\n",
    "intercept = 1.0\n",
    "    \n",
    "#define true_b \n",
    "true_b = zeros(p)\n",
    "true_b[1:10] .= rand(Normal(0, 0.25), k)\n",
    "shuffle!(true_b)\n",
    "correct_position = findall(!iszero, true_b)\n",
    "\n",
    "#simulate phenotypes (e.g. vector y)\n",
    "prob = GLM.linkinv.(l, intercept .+ X * true_b)\n",
    "clamp!(prob, -20, 20)\n",
    "y = [rand(d(i)) for i in prob]\n",
    "y = Float64.(y);\n",
    "\n",
    "# construct weight vector\n",
    "w = ones(p)\n",
    "w[correct_position] .= 2.0\n",
    "one_tenth = round(Int, p/10)\n",
    "idx = rand(1:p, one_tenth)\n",
    "w[idx] .= 2.0; #randomly set ~1/10 of all predictors to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_model = 10×4 DataFrame\n",
      " Row │ position  correct     unweighted  weighted\n",
      "     │ Int64     Float64     Float64     Float64\n",
      "─────┼─────────────────────────────────────────────\n",
      "   1 │     1264   0.252886     0.272761   0.282661\n",
      "   2 │     1506  -0.0939841    0.0       -0.119236\n",
      "   3 │     4866  -0.227394    -0.242687  -0.232847\n",
      "   4 │     5778  -0.510488    -0.512337  -0.501374\n",
      "   5 │     5833  -0.311969    -0.327575  -0.322659\n",
      "   6 │     5956  -0.0548168    0.0        0.0\n",
      "   7 │     6378  -0.0155173    0.0        0.0\n",
      "   8 │     7007  -0.123301     0.0        0.0\n",
      "   9 │     7063   0.0183886    0.0        0.0\n",
      "  10 │     7995  -0.102122    -0.118633  -0.132814\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run weighted and unweighted IHT\n",
    "unweighted = fit_iht(y, X, k=10, d=Normal(), l=IdentityLink(), verbose=false)\n",
    "weighted   = fit_iht(y, X, k=10, d=Normal(), l=IdentityLink(), verbose=false, weight=w)\n",
    "\n",
    "#check result\n",
    "compare_model = DataFrame(\n",
    "    position    = correct_position,\n",
    "    correct     = true_b[correct_position],\n",
    "    unweighted  = unweighted.beta[correct_position], \n",
    "    weighted    = weighted.beta[correct_position])\n",
    "@show compare_model\n",
    "println(\"\\n\")\n",
    "\n",
    "#clean up. Windows user must do this step manually (outside notebook/REPL)\n",
    "rm(\"tmp.bed\", force=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: weighted IHT found 1 extra predictor than non-weighted IHT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Multivariate IHT\n",
    "\n",
    "When there is multiple quantitative traits, analyzing them jointly is known to be superior than conducting multiple univariate-GWAS ([ref1](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0095923), [ref2](https://www.nature.com/articles/srep38837)). When `MendelIHT.jl` performs a multivariate analysis, \n",
    "\n",
    "+ IHT estimates effect of every SNP (covariate) conditioned on every other SNP across traits\n",
    "+ IHT outputs an estimated covariate matrix among traits\n",
    "+ IHT estimates proportion of trait variance explained by the genetic predictors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First simulate data\n",
    "\n",
    "With $r$ traits, each sample's phenotype $\\mathbf{y}_{i} \\in \\mathbb{R}^{n \\times 1}$ is simulated under\n",
    "\n",
    "$$\\mathbf{y}_{i}^{r \\times 1} \\sim N(\\mathbf{B}^{r \\times p}\\mathbf{x}_{i}^{p \\times 1}, \\ \\ \\Sigma_{r \\times r})$$\n",
    "\n",
    "This model assumes each sample is independent. The covariance among traits is specified by $\\Sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1000  # number of samples\n",
    "p = 10000 # number of SNPs\n",
    "k = 10    # number of causal SNPs\n",
    "r = 2     # number of traits\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2021)\n",
    "\n",
    "# simulate `.bed` file with no missing data\n",
    "x = simulate_random_snparray(\"multivariate.bed\", n, p)\n",
    "xla = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=true, scale=true) \n",
    "\n",
    "# intercept is the only nongenetic covariate\n",
    "z = ones(n, 1)\n",
    "intercepts = randn(r)' # each trait have different intercept\n",
    "\n",
    "# simulate response y, true model b, and the correct non-0 positions of b\n",
    "Y, true_Σ, true_b, correct_position = simulate_random_response(xla, k, r, Zu=z*intercepts, overlap=0)\n",
    "writedlm(\"multivariate.trait.cov\", true_Σ, ',')\n",
    "\n",
    "# create `.bim` and `.bam` files using phenotype\n",
    "make_bim_fam_files(x, Y, \"multivariate\")\n",
    "\n",
    "# also save phenotypes in separate file\n",
    "open(\"multivariate.phen\", \"w\") do io\n",
    "    for i in 1:n\n",
    "        println(io, Y[i, 1], \",\", Y[i, 2])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multivariate IHT, one can store multiple phenotpyes as extra columns in the `.fam` file. The first 10 rows of such a file is visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1\t0\t0\t1\t0.11302744016863553\t-0.7554260335256895\n",
      "2\t1\t0\t0\t1\t1.9891964726499531\t-0.45289178000961794\n",
      "3\t1\t0\t0\t1\t-3.439363162809635\t1.842833018537565\n",
      "4\t1\t0\t0\t1\t4.04029968770823\t3.4869907320499474\n",
      "5\t1\t0\t0\t1\t2.6565963705920983\t0.8105429321467232\n",
      "6\t1\t0\t0\t1\t-0.16399924513126818\t3.7682978263463855\n",
      "7\t1\t0\t0\t1\t2.274455154523604\t-0.3711839247250286\n",
      "8\t1\t0\t0\t1\t-2.0092329751410896\t-0.5206796904236644\n",
      "9\t1\t0\t0\t1\t-3.204538512643233\t2.6179242790617323\n",
      "10\t1\t0\t0\t1\t-3.8119298244977333\t3.212156674633338\n"
     ]
    }
   ],
   "source": [
    ";head multivariate.fam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenotypes can also be stored in a separate file. In this case, we require each subject's phenotype to occupy a different row. The file should not include a header line. Each row should be listed in the same order as in the PLINK and (for multivariate analysis) be comma separated. For example, the first 10 rows of such a file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11302744016863553,-0.7554260335256895\n",
      "1.9891964726499531,-0.45289178000961794\n",
      "-3.439363162809635,1.842833018537565\n",
      "4.04029968770823,3.4869907320499474\n",
      "2.6565963705920983,0.8105429321467232\n",
      "-0.16399924513126818,3.7682978263463855\n",
      "2.274455154523604,-0.3711839247250286\n",
      "-2.0092329751410896,-0.5206796904236644\n",
      "-3.204538512643233,2.6179242790617323\n",
      "-3.8119298244977333,3.212156674633338\n"
     ]
    }
   ],
   "source": [
    ";head multivariate.phen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run multivariate IHT\n",
    "\n",
    "The values specified in `path` corresponds to the total number of non-zero `k` to be tested in cross validation. Since we simulated 10 true genetic predictors, $k_{true} = 10$. Because non-genetic covariates are not specified, an intercept with automatically be included. Below give 3 ways of doing the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****                   MendelIHT Version 1.4.1                  ****\n",
      "****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****\n",
      "****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****\n",
      "****                                                            ****\n",
      "****                 Please cite our paper!                     ****\n",
      "****         https://doi.org/10.1093/gigascience/giaa044        ****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCross validating...100%|████████████████████████████████| Time: 0:00:03\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crossvalidation Results:\n",
      "\tk\tMSE\n",
      "\t1\t2894.951542220578\n",
      "\t2\t2404.2611566806236\n",
      "\t3\t2118.3458041809804\n",
      "\t4\t2003.0321765449573\n",
      "\t5\t1836.0954694153666\n",
      "\t6\t1810.8565487650512\n",
      "\t7\t1778.2006202357584\n",
      "\t8\t1739.5526656101028\n",
      "\t9\t1756.8768982533495\n",
      "\t10\t1749.0196878126512\n",
      "\t11\t1758.6127874414663\n",
      "\t12\t1780.6413839078918\n",
      "\t13\t1769.9360596010902\n",
      "\t14\t1802.66488874727\n",
      "\t15\t1802.0456455884719\n",
      "\t16\t1805.1748761415956\n",
      "\t17\t1834.8654353415632\n",
      "\t18\t1811.30688836247\n",
      "\t19\t1809.0070993669078\n",
      "\t20\t1813.2736422827502\n",
      "\n",
      "Best k = 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# genotypes stored in multivariate.bed and phenotypes in multivariate.phen\n",
    "mses = cross_validate(\"multivariate\", MvNormal, phenotypes=\"multivariate.phen\", path=1:20);\n",
    "\n",
    "# use columns 6 and 7 of .fam as phenotypes\n",
    "# mses = cross_validate(\"multivariate\", MvNormal, phenotypes=[6, 7], path=1:20)\n",
    "\n",
    "# run directly with xla and Y (note: transpose is necessary to make samples into columns)\n",
    "# mses = cv_iht(Matrix(Y'), Transpose(xla), path=1:20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best MSE is achieved at $k=8$. Let's run IHT with this estimate of $k$. Similarly, there are multiple ways to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****                   MendelIHT Version 1.4.1                  ****\n",
      "****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****\n",
      "****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****\n",
      "****                                                            ****\n",
      "****                 Please cite our paper!                     ****\n",
      "****         https://doi.org/10.1093/gigascience/giaa044        ****\n",
      "\n",
      "Running sparse Multivariate Gaussian regression\n",
      "Number of threads = 8\n",
      "Link functin = IdentityLink()\n",
      "Sparsity parameter (k) = 8\n",
      "Prior weight scaling = off\n",
      "Doubly sparse projection = off\n",
      "Debias = off\n",
      "Max IHT iterations = 200\n",
      "Converging when tol < 0.0001 and iteration ≥ 5:\n",
      "\n",
      "Iteration 1: loglikelihood = -2488.6435040107954, backtracks = 0, tol = 0.7246072304337687\n",
      "Iteration 2: loglikelihood = -2434.7808475264533, backtracks = 0, tol = 0.17873069127511898\n",
      "Iteration 3: loglikelihood = -2433.091980726226, backtracks = 0, tol = 0.029208315165883344\n",
      "Iteration 4: loglikelihood = -2433.0687518437962, backtracks = 0, tol = 0.0034098472530974555\n",
      "Iteration 5: loglikelihood = -2433.067802424958, backtracks = 0, tol = 0.0009427567101978172\n",
      "Iteration 6: loglikelihood = -2433.0677416028657, backtracks = 0, tol = 0.00025792112221606603\n",
      "Iteration 7: loglikelihood = -2433.067737220254, backtracks = 0, tol = 7.04657718794652e-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Compute time (sec):     0.11915302276611328\n",
       "Final loglikelihood:    -2433.067737220254\n",
       "Iterations:             7\n",
       "Trait 1's SNP PVE:      0.6029987163717704\n",
       "Trait 2's SNP PVE:      0.07348235785776043\n",
       "\n",
       "Estimated trait covariance:\n",
       "\u001b[1m2×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m trait1    \u001b[0m\u001b[1m trait2    \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────┼──────────────────────\n",
       "   1 │ 4.7186     0.0303161\n",
       "   2 │ 0.0303161  3.72355\n",
       "\n",
       "Trait 1: IHT estimated 6 nonzero SNP predictors\n",
       "\u001b[1m6×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │      134    -0.442256\n",
       "   2 │      442    -1.17973\n",
       "   3 │      450    -1.48389\n",
       "   4 │     1891    -1.44399\n",
       "   5 │     2557     0.828121\n",
       "   6 │     3243    -0.803224\n",
       "\n",
       "Trait 1: IHT estimated 1 non-genetic predictors\n",
       "\u001b[1m1×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │        1    -0.119153\n",
       "\n",
       "Trait 2: IHT estimated 2 nonzero SNP predictors\n",
       "\u001b[1m2×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │     1014    -0.391318\n",
       "   2 │     5214     0.376128\n",
       "\n",
       "Trait 2: IHT estimated 1 non-genetic predictors\n",
       "\u001b[1m1×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Position \u001b[0m\u001b[1m Estimated_β \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │        1     0.862081\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# genotypes stored in multivariate.bed and phenotypes in multivariate.phen\n",
    "result = iht(\"multivariate\", 8, MvNormal, phenotypes=\"multivariate.phen\")\n",
    "\n",
    "# genotypes stored in multivariate.bed use columns 6 and 7 of .fam as phenotypes\n",
    "# result = iht(\"multivariate\", 8, MvNormal, phenotypes=[6, 7])\n",
    "\n",
    "# run cross validation directly with xla and Y (note: transpose is necessary to make samples into columns)\n",
    "# result = fit_iht(Matrix(Y'), Transpose(xla), k=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convergence criteria can be tuned by keywords `tol` and `min_iter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check answers\n",
    "\n",
    "Estimated vs true first beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×2 Matrix{Float64}:\n",
       " -0.442256  -0.388067\n",
       " -1.17973   -1.24972\n",
       " -1.48389   -1.53835\n",
       "  0.0       -0.0034339\n",
       " -1.44399   -1.47163\n",
       "  0.828121   0.758756\n",
       " -0.803224  -0.847906"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β1 = result.beta[1, :]\n",
    "true_b1_idx = findall(!iszero, true_b[:, 1])\n",
    "[β1[true_b1_idx] true_b[true_b1_idx, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated vs true second beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Matrix{Float64}:\n",
       " -0.391318  -0.402269\n",
       "  0.376128   0.296183\n",
       "  0.0        0.125965"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β2 = result.beta[2, :]\n",
    "true_b2_idx = findall(!iszero, true_b[:, 2])\n",
    "[β2[true_b2_idx] true_b[true_b2_idx, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated vs true non genetic covariates (intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -0.119153  -0.172668\n",
       "  0.862081   0.729135"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result.c intercepts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated vs true covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×2 Matrix{Float64}:\n",
       " 4.7186     4.96944\n",
       " 0.0303161  0.162057\n",
       " 0.0303161  0.162057\n",
       " 3.72355    3.74153"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vec(result.Σ) vec(true_Σ)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** \n",
    "+ IHT found 9 true positives: 6/7 causal SNPs for trait 1 and 2/3 causal SNPs for trait 2\n",
    "+ Estimates for non-genetic covariates are close to the true values. \n",
    "+ Estimated trait covariance matrix closely match the true covariance\n",
    "+ The proportion of phenotypic trait variances explained by genotypes are 0.6 and 0.07."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples and functionalities\n",
    "\n",
    "Additional features are available as optional parameters in the [fit_iht](https://github.com/OpenMendel/MendelIHT.jl/blob/master/src/fit.jl#L37) function, but they should be treated as **experimental** features. Interested users are encouraged to explore them and please file issues on GitHub if you encounter a problem."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
