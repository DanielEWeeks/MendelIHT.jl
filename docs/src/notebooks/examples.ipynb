{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Examples\n",
    "\n",
    "In this section, we learn how to setup a basic analysis pipeline to analyze your GWAS data with MendelIHT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Press `]` to enter package manager mode and type the following (after `pkg>`):\n",
    "```\n",
    "(v1.0) pkg> add https://github.com/OpenMendel/SnpArrays.jl\n",
    "(v1.0) pkg> add https://github.com/OpenMendel/MendelSearch.jl\n",
    "(v1.0) pkg> add https://github.com/OpenMendel/MendelBase.jl\n",
    "(v1.0) pkg> add https://github.com/biona001/MendelIHT.jl\n",
    "```\n",
    "The order of installation is important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "For a typical user, your analysis pipeline should look like the following:\n",
    "\n",
    "### Step 1: Import data\n",
    "We use [SnpArrays.jl](https://openmendel.github.io/SnpArrays.jl/latest/) as backend to process genotype files. Internally, the genotype file is a memory mapped [SnpArray type](https://openmendel.github.io/SnpArrays.jl/stable/#SnpArray-1), which is used to compute summary statistics and does not consume RAM. In step 4 (particularly with function `L0_reg`, the genotype file must be converted to [SnpBitMatrix type](https://openmendel.github.io/SnpArrays.jl/stable/#SnpBitMatrix-1) to run linear algebra routines in MendelIHT, and this consumes $n \\times p \\times 2$ bits of RAM. \n",
    "\n",
    "Non-genetic predictors should be read into Julia in the standard way, and should be stored as a **matrix** of type Float64 (i.e. `Array{Float64, 2}`. One should include the intercept as the first column, but an intercept is not required to run IHT. \n",
    "\n",
    "#### Example 1.1: Reading Genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using SnpArrays, MendelIHT\n",
    "x = SnpArray(\"../data/test1.bed\")\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "\n",
    "    (1) MendelIHT.jl assumes there are **NO missing genotypes**, and (2) the trios (`.bim`, `.bed`, `.fam`) must all be present in the same directory. \n",
    "    \n",
    "#### Example 1.2: Reading non-genetic covariate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Array{Float64,2}:\n",
       " 1.0   1.01969 \n",
       " 1.0  -0.979706\n",
       " 1.0   1.01969 \n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0   1.01969 \n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0   1.01969 \n",
       " 1.0  -0.979706\n",
       " ⋮             \n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0   1.01969 \n",
       " 1.0   1.01969 \n",
       " 1.0   1.01969 \n",
       " 1.0  -0.979706\n",
       " 1.0   1.01969 \n",
       " 1.0  -0.979706\n",
       " 1.0  -0.979706\n",
       " 1.0   1.01969 \n",
       " 1.0  -0.979706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DelimitedFiles, Statistics\n",
    "z = readdlm(\"../data/test1_covariates.txt\") # 1st column intercept, 2nd column sex\n",
    "\n",
    "# standardize all covariates (other than intercept) to mean 0 variance 1\n",
    "for i in 2:size(z, 2)\n",
    "    col_mean = mean(z[:, i])\n",
    "    col_std  = std(z[:, i])\n",
    "    z[:, i] .= (z[:, i] .- col_mean) ./ col_std\n",
    "end\n",
    "\n",
    "z #first column intercept, and 2nd column is the standardized sex covariate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "\n",
    "    Except for the intercept, one should standardize all (including binary and categorical) covarariates. This ensures equal penalization for all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Decide different model sizes you wish to test\n",
    "This means deciding how many SNPs *may* be associated with the trait. You store all the model sizes you want to test in a vector typically called `path`. Then you decide how many fold of cross validation you need (more = higher accuracy, but longer compute time. Typically we do 3~5 fold). \n",
    "\n",
    "#### Example 2.1\n",
    "A complex trait such as obesity may have 100 associative SNPs. Thus we test models $k = \\{1, 2, ..., 100\\}$ as possible models. Then we run 5 fold [cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) to minimize overfitting. Of course, one is free to choose any number of folds and any model sizes, but the computational complexity of running $a$ models across $b$ folds scales as $\\mathcal{O}(ab)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 5\n",
       " 4\n",
       " 4\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 3\n",
       " 1\n",
       " ⋮\n",
       " 3\n",
       " 1\n",
       " 5\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 5\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 1\n",
       " 4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = collect(1:100)\n",
    "num_folds = 5\n",
    "folds = rand(1:num_folds, size(x, 1)) #vector partitioning x into 5 disjoint subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### Step 3: Call cv_iht to run cross validation across the different models\n",
    "\n",
    "This picks the best model size you specified through cross validation\n",
    "### Step 4: Run `L0_reg` on the best model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using SnpArrays, MendelIHT\n",
    "x = SnpArray(\"../data/test1.bed\")\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999997"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DelimitedFiles, Statistics\n",
    "z = readdlm(\"../data/test1_covariates.txt\") # 1st column intercept, 2nd column sex\n",
    "\n",
    "# standardize all covariates (other than intercept) to mean 0 variance 1\n",
    "for i in 2:size(z, 2)\n",
    "    col_mean = mean(z[:, i])\n",
    "    col_std  = std(z[:, i])\n",
    "    z[:, i] .= (z[:, i] .- col_mean) ./ col_std\n",
    "end\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```Julia\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
