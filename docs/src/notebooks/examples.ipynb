{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Examples\n",
    "\n",
    "Here we give numerous example analysis of GWAS data with MendelIHT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.0.3\n",
      "Commit 099e826241 (2018-12-18 01:34 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin14.5.0)\n",
      "  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "# machine information for reproducibility\n",
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first add workers needed for parallel computing. Add only as many CPU cores available\n",
    "using Distributed\n",
    "addprocs(4)\n",
    "\n",
    "#load necessary packages for running all examples below\n",
    "using MendelIHT\n",
    "using SnpArrays\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using GLM\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: How to Import Data\n",
    "\n",
    "We use [SnpArrays.jl](https://openmendel.github.io/SnpArrays.jl/latest/) as backend to process genotype files. Internally, the genotype file is a memory mapped [SnpArray](https://openmendel.github.io/SnpArrays.jl/stable/#SnpArray-1), which will not be loaded into RAM. If you wish to run `L0_reg`, you need to convert a SnpArray into a [SnpBitMatrix](https://openmendel.github.io/SnpArrays.jl/stable/#SnpBitMatrix-1), which consumes $n \\times p \\times 2$ bits of RAM. Non-genetic predictors should be read into Julia in the standard way, and should be stored as an `Array{Float64, 2}`. One should include the intercept (typically in the first column), but an intercept is not required to run IHT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate example data (to be imported later)\n",
    "\n",
    "First we simulate an example PLINK trio (`.bim`, `.bed`, `.fam`) and non-genetic covariates, then we illustrate how to import them. For genotype matrix simulation, we simulate under the model:\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rows and columns\n",
    "n = 1000\n",
    "p = 10000\n",
    "\n",
    "#random seed\n",
    "Random.seed!(1111)\n",
    "\n",
    "# simulate random `.bed` file\n",
    "x = simulate_random_snparray(n, p, \"example.bed\")\n",
    "\n",
    "# create accompanying `.bim`, `.fam` files (randomly generated)\n",
    "make_bim_fam_files(x, ones(n), \"example\")\n",
    "\n",
    "# simulate non-genetic covariates (in this case, we include intercept and sex)\n",
    "z = [ones(n, 1) rand(0:1, n)]\n",
    "writedlm(\"example_nongenetic_covariates.txt\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Genotype data and Non-Genetic Covariates from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Array{Float64,2}:\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " ⋮       \n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = SnpArray(\"example.bed\")\n",
    "z = readdlm(\"example_nongenetic_covariates.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "\n",
    "    (1) MendelIHT.jl assumes there are **NO missing genotypes**, (2) 1 always encode the minor allele, and (3) the trios (`.bim`, `.bed`, `.fam`) are all be present in the same directory. \n",
    "    \n",
    "### Standardizing Non-Genetic Covariates.\n",
    "\n",
    "We recommend standardizing all genetic and non-genetic covarariates (including binary and categorical), except for the intercept. This ensures equal penalization for all predictors. For genotype matrix, `SnpBitMatrix` efficiently achieves this standardization. For non-genetic covariates, we use the built-in function `standardize!`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Array{Float64,2}:\n",
       " 1.0   1.0015  \n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0   1.0015  \n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0   1.0015  \n",
       " 1.0  -0.997503\n",
       " 1.0   1.0015  \n",
       " 1.0   1.0015  \n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0   1.0015  \n",
       " ⋮             \n",
       " 1.0  -0.997503\n",
       " 1.0   1.0015  \n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0  -0.997503\n",
       " 1.0   1.0015  \n",
       " 1.0  -0.997503"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SnpBitMatrix can automatically standardizes .bed file (without extra memory) and behaves like a matrix\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n",
    "\n",
    "# using view is important for correctness\n",
    "standardize!(@view(z[:, 2:end])) \n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove simulated data once they are no longer needed\n",
    "rm(\"example.bed\", force=true)\n",
    "rm(\"example.bim\", force=true)\n",
    "rm(\"example.fam\", force=true)\n",
    "rm(\"example_nongenetic_covariates.txt\", force=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 2: Running IHT on Quantitative Traits\n",
    "\n",
    "Quantitative traits are continuous phenotypes whose distribution can be modeled by the normal distribution. Then using the genotype matrix $\\mathbf{X}$ and phenotype vector $\\mathbf{y}$, we want to recover $\\beta$ such that $\\mathbf{y} \\approx \\mathbf{X}\\beta$. In this example, we assume we know the true sparsity level `k`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 1: Import data\n",
    "\n",
    "In Example 1 we illustrated how to import data into Julia. So here we use simulated data ([code](https://github.com/biona001/MendelIHT.jl/blob/master/src/simulate_utilities.jl#L107)) because, only then, can we compare IHT's result to the true solution. Below we simulate a GWAS data with $n=1000$ patients and $p=10000$ SNPs. Here the quantitative trait vector are affected by $k = 10$ causal SNPs, with no non-genetic confounders. \n",
    "\n",
    "In this example, our model is simulated as:\n",
    "\n",
    "$$y_i \\sim \\mathbf{x}_i^T\\mathbf{\\beta} + \\epsilon_i$$\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "$$\\epsilon_i \\sim \\rm N(0, 1)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define model dimensions, true model size, distribution, and link functions\n",
    "n = 1000\n",
    "p = 10000\n",
    "k = 10\n",
    "d = Normal\n",
    "l = canonicallink(d())\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2019) \n",
    "\n",
    "# simulate SNP matrix, store the result in a file called tmp.bed\n",
    "x = simulate_random_snparray(n, p, \"tmp.bed\")\n",
    "\n",
    "#construct the SnpBitMatrix type (needed for L0_reg() and simulate_random_response() below)\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true); \n",
    "\n",
    "# intercept is the only nongenetic covariate\n",
    "z = ones(n, 1) \n",
    "\n",
    "# simulate response y, true model b, and the correct non-0 positions of b\n",
    "y, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run cross validation to determine best model size\n",
    "\n",
    "To run `cv_iht`, you must specify `path` and `num_fold`, defined below:\n",
    "\n",
    "+ `path` are all the model sizes you wish to test, stored in a vector of integers.\n",
    "+ `num_fold` indicates how many disjoint partitions of the samples is requested. \n",
    "\n",
    "By default, we partition the training/testing data randomly, but you can change this by inputing the `fold` vector as optional argument. In this example we tested $k = 1, 2, ..., 20$ across 3 fold cross validation. This is equivalent to running IHT across 60 different models, and hence, is ideal for parallel computing (which you specify by `parallel=true`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crossvalidation Results:\n",
      "\tk\tMSE\n",
      "\t1\t1927.0765190526674\n",
      "\t2\t1443.8788742220863\n",
      "\t3\t1080.041135323195\n",
      "\t4\t862.2385953735204\n",
      "\t5\t705.1014346627649\n",
      "\t6\t507.3949359364219\n",
      "\t7\t391.96868764622843\n",
      "\t8\t368.45440222003174\n",
      "\t9\t350.642794092518\n",
      "\t10\t345.8380848576577\n",
      "\t11\t350.5188147284578\n",
      "\t12\t359.42391568519577\n",
      "\t13\t363.70956969599075\n",
      "\t14\t377.30732985896975\n",
      "\t15\t381.0310879522694\n",
      "\t16\t392.56439238382615\n",
      "\t17\t396.81166049333797\n",
      "\t18\t397.3010019298764\n",
      "\t19\t406.47023764639624\n",
      "\t20\t410.4672260807978\n"
     ]
    }
   ],
   "source": [
    "path = collect(1:20)\n",
    "num_folds = 3\n",
    "mses = cv_iht(d(), l, x, z, y, 1, path, num_folds, parallel=true); #here 1 is for number of groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note \n",
    "\n",
    "    **DO NOT remove** intermediate files with random filenames as generated by `cv_iht()`. These are necessary auxiliary files that will be automatically removed when cross validation completes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! tip\n",
    "\n",
    "    Because Julia employs a JIT compiler, the first round of any function call run will always take longer and consume extra memory. Therefore it is advised to always run a small \"test example\" (such as this one!) before running cross validation on a large dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run full model on the best estimated model size \n",
    "\n",
    "`cv_iht` finished in less than a minute. \n",
    "\n",
    "According to our cross validation result, the best model size that minimizes deviance residuals (i.e. MSE on the q-th subset of samples) is attained at $k = 10$. That is, cross validation detected that we need 10 SNPs to achieve the best model size. Using this information, one can re-run the IHT algorithm on the *full* dataset to obtain the best estimated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 10 nonzero SNP predictors and 0 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.4252500534057617\n",
       "Final loglikelihood:    -1406.8807653835697\n",
       "Iterations:             6\n",
       "\n",
       "Selected genetic predictors:\n",
       "10×2 DataFrame\n",
       "│ Row │ Position │ Estimated_β │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼──────────┼─────────────┤\n",
       "│ 1   │ 853      │ -1.24117    │\n",
       "│ 2   │ 877      │ -0.234676   │\n",
       "│ 3   │ 924      │ 0.82014     │\n",
       "│ 4   │ 2703     │ 0.583403    │\n",
       "│ 5   │ 4241     │ 0.298304    │\n",
       "│ 6   │ 4783     │ -1.14459    │\n",
       "│ 7   │ 5094     │ 0.673012    │\n",
       "│ 8   │ 5284     │ -0.709736   │\n",
       "│ 9   │ 7760     │ 0.16866     │\n",
       "│ 10  │ 8255     │ 1.08117     │\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "0×2 DataFrame\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_est = argmin(mses)\n",
    "result = L0_reg(x, xbm, z, y, 1, k_est, d(), l) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 (only for simulated data): Check final model against simulation\n",
    "\n",
    "Since all our data and model was simulated, we can see how well `cv_iht` combined with `L0_reg` estimated the true model. For this example, we find that IHT found every simulated predictor, with 0 false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_model = 10×2 DataFrame\n",
      "│ Row │ true_β   │ estimated_β │\n",
      "│     │ Float64  │ Float64     │\n",
      "├─────┼──────────┼─────────────┤\n",
      "│ 1   │ -1.29964 │ -1.24117    │\n",
      "│ 2   │ -0.2177  │ -0.234676   │\n",
      "│ 3   │ 0.786217 │ 0.82014     │\n",
      "│ 4   │ 0.599233 │ 0.583403    │\n",
      "│ 5   │ 0.283711 │ 0.298304    │\n",
      "│ 6   │ -1.12537 │ -1.14459    │\n",
      "│ 7   │ 0.693374 │ 0.673012    │\n",
      "│ 8   │ -0.67709 │ -0.709736   │\n",
      "│ 9   │ 0.14727  │ 0.16866     │\n",
      "│ 10  │ 1.03477  │ 1.08117     │\n"
     ]
    }
   ],
   "source": [
    "compare_model = DataFrame(\n",
    "    true_β      = true_b[correct_position], \n",
    "    estimated_β = result.beta[correct_position])\n",
    "@show compare_model\n",
    "\n",
    "#clean up. Windows user must do this step manually (outside notebook/REPL)\n",
    "rm(\"tmp.bed\", force=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Logistic Regression Controlling for Sex\n",
    "\n",
    "We show how to use IHT to handle case-control studies, while handling non-genetic covariates. In this example, we fit a logistic regression model with IHT using simulated case-control data, while controling for sex as a nongenetic covariate. \n",
    "\n",
    "### Step 1: Import Data\n",
    "\n",
    "Again we use a simulated model:\n",
    "\n",
    "$$y_i \\sim \\rm Bernoulli(\\mathbf{x}_i^T\\mathbf{\\beta})$$\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 1)$$\n",
    "$$\\beta_{\\rm intercept} = 1$$\n",
    "$$\\beta_{\\rm sex} = 1.5$$\n",
    "\n",
    "We assumed there are $k=8$ genetic predictors and 2 non-genetic predictors (intercept and sex) that affects the trait. The simulation code in our package does not yet handle simulations with non-genetic predictors, so we must simulate these phenotypes manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define model dimensions, true model size, distribution, and link functions\n",
    "n = 1000\n",
    "p = 10000\n",
    "k = 10\n",
    "d = Bernoulli\n",
    "l = canonicallink(d())\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2019)\n",
    "\n",
    "# construct SnpArray and SnpBitMatrix\n",
    "x = simulate_random_snparray(n, p, \"tmp.bed\")\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n",
    "\n",
    "# nongenetic covariate: first column is the intercept, second column is sex: 0 = male 1 = female\n",
    "z = ones(n, 2) \n",
    "z[:, 2] .= rand(0:1, n)\n",
    "\n",
    "# randomly set genetic predictors\n",
    "true_b = zeros(p) \n",
    "true_b[1:k-2] = randn(k-2)\n",
    "shuffle!(true_b)\n",
    "\n",
    "# find correct position of genetic predictors\n",
    "correct_position = findall(!iszero, true_b)\n",
    "\n",
    "# define effect size of non-genetic predictors: intercept & sex\n",
    "true_c = [1.0; 1.5] \n",
    "\n",
    "# simulate phenotype using genetic and nongenetic predictors\n",
    "prob = linkinv.(l, xbm * true_b .+ z * true_c)\n",
    "y = [rand(d(i)) for i in prob]\n",
    "y = Float64.(y); # y must be floating point numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run cross validation to determine best model size\n",
    "\n",
    "To run `cv_iht`, you must specify `path` and `num_fold`, defined below:\n",
    "\n",
    "+ `path` are all the model sizes you wish to test, stored in a vector of integers.\n",
    "+ `num_fold` indicates how many disjoint partitions of the samples is requested. \n",
    "\n",
    "By default, we partition the training/testing data randomly, but you can change this by inputing the `fold` vector as optional argument. In this example we tested $k = 1, 2, ..., 20$ across 3 fold cross validation. This is equivalent to running IHT across 60 different models, and hence, is ideal for parallel computing (which you specify by `parallel=true`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crossvalidation Results:\n",
      "\tk\tMSE\n",
      "\t1\t391.44426892225727\n",
      "\t2\t365.7520496496987\n",
      "\t3\t332.3801926093215\n",
      "\t4\t273.2081512206048\n",
      "\t5\t253.31631985207758\n",
      "\t6\t234.93701288953315\n",
      "\t7\t221.997334181244\n",
      "\t8\t199.01688783420346\n",
      "\t9\t208.31087723164197\n",
      "\t10\t216.00575628120708\n",
      "\t11\t227.91834469184545\n",
      "\t12\t242.42456871743065\n",
      "\t13\t261.46346209331466\n",
      "\t14\t263.5229307137862\n",
      "\t15\t283.30379378951073\n",
      "\t16\t328.2771991160804\n",
      "\t17\t290.4512419547228\n",
      "\t18\t350.3516280657363\n",
      "\t19\t361.61016297810295\n",
      "\t20\t418.2370935226805\n"
     ]
    }
   ],
   "source": [
    "path = collect(1:20)\n",
    "num_folds = 3\n",
    "mses = cv_iht(d(), l, x, z, y, 1, path, num_folds, parallel=true); #here 1 is for number of groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! tip\n",
    "\n",
    "    In our experience, using the `ProbitLink` for logistic regressions deliver better results than `LogitLink` (which is the canonical link). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run full model on the best estimated model size \n",
    "\n",
    "`cv_iht` finished in about a minute. \n",
    "\n",
    "Cross validation have declared that $k_{best} = 8$. Using this information, one can re-run the IHT algorithm on the *full* dataset to obtain the best estimated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 6 nonzero SNP predictors and 2 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     1.7605140209197998\n",
       "Final loglikelihood:    -290.4509381564733\n",
       "Iterations:             37\n",
       "\n",
       "Selected genetic predictors:\n",
       "6×2 DataFrame\n",
       "│ Row │ Position │ Estimated_β │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼──────────┼─────────────┤\n",
       "│ 1   │ 1152     │ 0.966731    │\n",
       "│ 2   │ 1576     │ 1.56183     │\n",
       "│ 3   │ 3411     │ 0.87674     │\n",
       "│ 4   │ 5765     │ -1.75611    │\n",
       "│ 5   │ 5992     │ -2.04506    │\n",
       "│ 6   │ 8781     │ 0.760213    │\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "2×2 DataFrame\n",
       "│ Row │ Position │ Estimated_β │\n",
       "│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼──────────┼─────────────┤\n",
       "│ 1   │ 1        │ 0.709909    │\n",
       "│ 2   │ 2        │ 1.65049     │"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_est = argmin(mses)\n",
    "result = L0_reg(x, xbm, z, y, 1, k_est, d(), l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 (only for simulated data): Check final model against simulation\n",
    "\n",
    "Since all our data and model was simulated, we can see how well `cv_iht` combined with `L0_reg` estimated the true model. For this example, we find that IHT found both nongenetic predictor, but missed 2 genetic predictors. The 2 genetic predictors that we missed had much smaller effect size, so given that we only had 1000 samples, this is hardly surprising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_model_genetics = 8×2 DataFrame\n",
      "│ Row │ true_β   │ estimated_β │\n",
      "│     │ Float64  │ Float64     │\n",
      "├─────┼──────────┼─────────────┤\n",
      "│ 1   │ 0.961937 │ 0.966731    │\n",
      "│ 2   │ 0.189267 │ 0.0         │\n",
      "│ 3   │ 1.74008  │ 1.56183     │\n",
      "│ 4   │ 0.879004 │ 0.87674     │\n",
      "│ 5   │ 0.213066 │ 0.0         │\n",
      "│ 6   │ -1.74663 │ -1.75611    │\n",
      "│ 7   │ -1.93402 │ -2.04506    │\n",
      "│ 8   │ 0.632786 │ 0.760213    │\n",
      "compare_model_nongenetics = 2×2 DataFrame\n",
      "│ Row │ true_c  │ estimated_c │\n",
      "│     │ Float64 │ Float64     │\n",
      "├─────┼─────────┼─────────────┤\n",
      "│ 1   │ 1.0     │ 0.709909    │\n",
      "│ 2   │ 1.5     │ 1.65049     │\n"
     ]
    }
   ],
   "source": [
    "compare_model_genetics = DataFrame(\n",
    "    true_β      = true_b[correct_position], \n",
    "    estimated_β = result.beta[correct_position])\n",
    "\n",
    "compare_model_nongenetics = DataFrame(\n",
    "    true_c      = true_c[1:2], \n",
    "    estimated_c = result.c[1:2])\n",
    "\n",
    "@show compare_model_genetics\n",
    "@show compare_model_nongenetics\n",
    "\n",
    "#clean up. Windows user must do this step manually (outside notebook/REPL)\n",
    "rm(\"tmp.bed\", force=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Poisson Regression with Acceleration (i.e. debias)\n",
    "\n",
    "In this example, we show how debiasing can potentially achieve dramatic speedup. Our model is:\n",
    "\n",
    "$$y_i \\sim \\rm Poisson(\\mathbf{x}_i^T \\mathbf{\\beta})$$\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 0.3)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define model dimensions, true model size, distribution, and link functions\n",
    "n = 1000\n",
    "p = 10000\n",
    "k = 10\n",
    "d = Poisson\n",
    "l = canonicallink(d())\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2019)\n",
    "\n",
    "# construct SnpArray, SnpBitMatrix, and intercept\n",
    "x = simulate_random_snparray(n, p, \"tmp.bed\")\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n",
    "z = ones(n, 1) \n",
    "\n",
    "# simulate response, true model b, and the correct non-0 positions of b\n",
    "y, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Compare Reconstruction Result\n",
    "\n",
    "First we show that, with or without debiasing, we obtain comparable results with `L0_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_debias  = L0_reg(x, xbm, z, y, 1, k, d(), l, debias=false)\n",
    "yes_debias = L0_reg(x, xbm, z, y, 1, k, d(), l, debias=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_model = 10×4 DataFrame\n",
      "│ Row │ position │ true_β     │ no_debias_β │ yes_debias_β │\n",
      "│     │ Int64    │ Float64    │ Float64     │ Float64      │\n",
      "├─────┼──────────┼────────────┼─────────────┼──────────────┤\n",
      "│ 1   │ 853      │ -0.389892  │ -0.384161   │ -0.38744     │\n",
      "│ 2   │ 877      │ -0.0653099 │ 0.0         │ 0.0          │\n",
      "│ 3   │ 924      │ 0.235865   │ 0.246213    │ 0.240514     │\n",
      "│ 4   │ 2703     │ 0.17977    │ 0.237651    │ 0.225127     │\n",
      "│ 5   │ 4241     │ 0.0851134  │ 0.0         │ 0.0894244    │\n",
      "│ 6   │ 4783     │ -0.33761   │ -0.300663   │ -0.307515    │\n",
      "│ 7   │ 5094     │ 0.208012   │ 0.223384    │ 0.215149     │\n",
      "│ 8   │ 5284     │ -0.203127  │ -0.225593   │ -0.209308    │\n",
      "│ 9   │ 7760     │ 0.0441809  │ 0.0         │ 0.0          │\n",
      "│ 10  │ 8255     │ 0.310431   │ 0.287363    │ 0.301717     │\n"
     ]
    }
   ],
   "source": [
    "compare_model = DataFrame(\n",
    "    position    = correct_position,\n",
    "    true_β      = true_b[correct_position], \n",
    "    no_debias_β = no_debias.beta[correct_position],\n",
    "    yes_debias_β = yes_debias.beta[correct_position])\n",
    "@show compare_model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Speed and Memory Usage\n",
    "\n",
    "Now we illustrate that debiasing may dramatically reduce computational time (in this case ~50%), at a cost of increasing the memory usage. In practice, this extra memory usage hardly matters because the matrix size will dominate for larger problems. See [our paper for complete benchmark figure.](https://www.biorxiv.org/content/10.1101/697755v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.16 MiB\n",
       "  allocs estimate:  738\n",
       "  --------------\n",
       "  minimum time:     678.133 ms (0.00% GC)\n",
       "  median time:      718.579 ms (0.00% GC)\n",
       "  mean time:        718.396 ms (0.05% GC)\n",
       "  maximum time:     749.206 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          21\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark L0_reg(x, xbm, z, y, 1, k, d(), l, debias=false) seconds=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.62 MiB\n",
       "  allocs estimate:  1135\n",
       "  --------------\n",
       "  minimum time:     333.945 ms (0.00% GC)\n",
       "  median time:      344.313 ms (0.00% GC)\n",
       "  mean time:        344.025 ms (0.10% GC)\n",
       "  maximum time:     350.126 ms (0.87% GC)\n",
       "  --------------\n",
       "  samples:          44\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark L0_reg(x, xbm, z, y, 1, k, d(), l, debias=true) seconds=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean up. Windows user must do this step manually (outside notebook/REPL)\n",
    "rm(\"tmp.bed\", force=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples and functionalities\n",
    "\n",
    "We invite users to experiment with additional functionalities. We explored a significant portion of them in our manuscript, with [reproducible code](https://github.com/biona001/MendelIHT.jl/tree/master/figures). This includes:\n",
    "\n",
    "+ Modeling some exotic distributions and using noncanonical link functions [listed here](https://biona001.github.io/MendelIHT.jl/latest/man/getting_started/#Supported-GLM-models-and-Link-functions-1)\n",
    "+ Modeling SNP-SNP or SNP-environment interaction effects by explicitly including them in the nongenetic covariates `z`.\n",
    "+ Doubly sparse projection (requires group information)\n",
    "+ Weighted projections to favor certain SNPs (requires weight information)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
