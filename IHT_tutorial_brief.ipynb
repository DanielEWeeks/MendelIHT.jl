{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHT.jl tutorial (brief)\n",
    "\n",
    "In this tutorial we explore some of the functionality of the IHT.jl package, which implements iterative hard threhsolding on floating point arrays and binary PLINK data. \n",
    "\n",
    "The first part of the tutorial demonstrates how to handle floating point data. Later we will show how to use [PLINK binary genotype files](http://pngu.mgh.harvard.edu/~purcell/plink/binary.shtml). IHT.jl offers two parallel computational frameworks for PLINK data: multicore CPUs or massively parallel GPUs. Although this tutorial features the CPU version, instructions for GPU use are included.\n",
    "\n",
    "This tutorial targets novice users. Advanced users are encouraged to read the full tutorial located at `~/.julia/v0.4/IHT/IHT_tutorial_full.ipynb`.\n",
    "\n",
    "We begin by adding processors and loading libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addprocs(5)         # for later parallel XV\n",
    "using IHT, PLINK    # PLINK.jl handles PLINK files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will use a script to simulate all data and variables. The default location is given in `simpath`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invoking transpose with outfile /Users/kkeys/Desktop/tbed_1.bed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation complete.\n"
     ]
    }
   ],
   "source": [
    "simpath = expanduser(\"~/.julia/v0.4/IHT/sim/tutorial_simulation.jl\")\n",
    "include(simpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script `tutorial_simulation.jl` generates floating point data `x` with a response vector `y`.\n",
    "\n",
    "Using `x`, we now run iterative hard thresholding to capture the best model of size `k = 10`. The function call is `L0_reg`, which returns an object `output` with the following fields:\n",
    "\n",
    "- `output.time`, the compute time in seconds\n",
    "- `output.iter`, the number of iterations taken until convergence\n",
    "- `output.loss`, the residual sum of squares at convergence\n",
    "- `output.beta`, the $\\boldsymbol{\\beta}$ vector at convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Compute time:   1.08264232\n",
       "Final loss:     25.12432779234657\n",
       "Iterations::    13\n",
       "IHT estimated a vector of type Array{Float64,1} with 10 nonzeroes.\n",
       "10×2 DataFrames.DataFrame\n",
       "│ Row │ Predictor │ β         │\n",
       "├─────┼───────────┼───────────┤\n",
       "│ 1   │ 3310      │ -0.346533 │\n",
       "│ 2   │ 4460      │ 0.612489  │\n",
       "│ 3   │ 5861      │ 0.175425  │\n",
       "│ 4   │ 9731      │ -0.494717 │\n",
       "│ 5   │ 11294     │ 1.36302   │\n",
       "│ 6   │ 11378     │ -0.588894 │\n",
       "│ 7   │ 14217     │ 0.154568  │\n",
       "│ 8   │ 15118     │ 0.0318823 │\n",
       "│ 9   │ 19815     │ 0.374349  │\n",
       "│ 10  │ 23295     │ -1.38392  │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = L0_reg(x,y,k)  # run IHT with data x, response y, and desired model size k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the results against the true model `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x2 Array{Float64,2}:\n",
       " -0.341588  -0.346533 \n",
       "  0.612107   0.612489 \n",
       "  0.17465    0.175425 \n",
       " -0.494423  -0.494717 \n",
       "  1.36306    1.36302  \n",
       " -0.58849   -0.588894 \n",
       "  0.155924   0.154568 \n",
       "  0.031168   0.0318823\n",
       "  0.374056   0.374349 \n",
       " -1.38168   -1.38392  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk = copy(output.beta)  # copy the estimated β for later use\n",
    "[β[bidx] bk[bidx]]      # compare true and estimated coefficients; b, bidx contain true model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that IHT returns all the correct nonzero coefficients. The coefficient values themselves are fairly close to their originals. We expect this since `s = 0.1` does not yield a very noisy `y`. Observe what happens when we use a noisier response `y2` simulated from the same data `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x3 Array{Float64,2}:\n",
       " -0.341588  -0.346533   -0.326644\n",
       "  0.612107   0.612489    0.604358\n",
       "  0.17465    0.175425    0.0     \n",
       " -0.494423  -0.494717   -0.612899\n",
       "  1.36306    1.36302     1.39415 \n",
       " -0.58849   -0.588894   -0.613471\n",
       "  0.155924   0.154568    0.0     \n",
       "  0.031168   0.0318823   0.0     \n",
       "  0.374056   0.374349    0.0     \n",
       " -1.38168   -1.38392    -1.33059 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = L0_reg(x, y2, k)      # run IHT with noisier response y2\n",
    "bk2     = copy(output2.beta)    # copy results for later use\n",
    "[β[bidx] bk[bidx] bk2[bidx]]    # compare analysis of y, y2 against truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that `b` is the original model, `bk` is the estimated model with low noise (`s = 0.1`), and `bk2` is the estimated model with high noise (`s = 5`). The coefficient values are less accurate, and several nonzero values are not recovered. Note that a failure to recover the correct model does not indicate that IHT model selection performance is necessarily bad; the high noise level makes accurate estimation of the model quite difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT for GWAS\n",
    "\n",
    "IHT.jl interfaces with [PLINK.jl](https://github.com/klkeys/PLINK.jl) for GWAS analysis. PLINK.jl handles PLINK binary genotype files (BED files). In this section of the tutorial we will demonstrate GWAS analysis with IHT.jl on simulated binary genotype data. Luckily, PLINK.jl ships with some simulated binary data.\n",
    "\n",
    "The call to IHT is the same as with the floating point `x`. Here we use simulated binary genotype data housed in `xbed` and a corresponding simulated response `ybed`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Compute time:   7.346981444\n",
       "Final loss:     25.07111852912545\n",
       "Iterations::    13\n",
       "IHT estimated a vector of type Array{Float64,1} with 10 nonzeroes.\n",
       "10×2 DataFrames.DataFrame\n",
       "│ Row │ Predictor │ β         │\n",
       "├─────┼───────────┼───────────┤\n",
       "│ 1   │ 650       │ -0.179789 │\n",
       "│ 2   │ 3288      │ 1.80377   │\n",
       "│ 3   │ 6035      │ 0.137861  │\n",
       "│ 4   │ 6931      │ -0.854269 │\n",
       "│ 5   │ 7949      │ 1.02445   │\n",
       "│ 6   │ 8886      │ 0.0930143 │\n",
       "│ 7   │ 14799     │ -0.439589 │\n",
       "│ 8   │ 14984     │ -1.46272  │\n",
       "│ 9   │ 19620     │ 0.705692  │\n",
       "│ 10  │ 19872     │ 0.0107966 │"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = L0_reg(xbed, ybed, k) # run IHT with BED files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let us compare the estimated model to the simulated one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x2 Array{Float64,2}:\n",
       " -0.176622   -0.179789 \n",
       "  1.80336     1.80377  \n",
       "  0.135377    0.137861 \n",
       " -0.85557    -0.854269 \n",
       "  1.022       1.02445  \n",
       "  0.0903269   0.0930143\n",
       " -0.442234   -0.439589 \n",
       " -1.46398    -1.46272  \n",
       "  0.705111    0.705692 \n",
       "  0.0109637   0.0107966"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk = copy(output.beta)      # copy the beta for later use\n",
    "[bbed[bidxbed] bk[bidxbed]] # did we get the correct model and coefficient values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation\n",
    "\n",
    "These exploratory efforts are admittedly not illuminating. In a realistic setting, we wouldn't know the correct model size `k = 10`. IHT handles this by crossvalidating the model size with `cv_iht`. For example, to perform 5-fold over a range of models given by pathidx, we would use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "An IHTCrossvalidationResults object with the following results:\n",
       "Minimum MSE 16.161813213014682 occurs at k = 6.\n",
       "Best model β has the following nonzero coefficients:\n",
       "6×2 DataFrames.DataFrame\n",
       "│ Row │ Predictor │ β         │\n",
       "├─────┼───────────┼───────────┤\n",
       "│ 1   │ 3310      │ -0.33289  │\n",
       "│ 2   │ 4460      │ 0.615219  │\n",
       "│ 3   │ 9731      │ -0.60089  │\n",
       "│ 4   │ 11294     │ 1.40044   │\n",
       "│ 5   │ 11378     │ -0.613623 │\n",
       "│ 6   │ 23295     │ -1.35266  │\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_output = cv_iht(x, y2, pathidx, nfolds, folds=folds, pids=pids) # nfolds = 5, pathidx = 1:20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IHT.jl can use PLINK files directly in parallel crossvalidation. However, the interface of `cv_iht` changes in two crucial ways. Firstly, instead of feeding the data `x` and `y` directly, we must point `cv_iht` to the locations of all data files stored on disk. Secondly, all data except the covariates must be stored in *binary* format.\n",
    "\n",
    "Storing data in binary format is actually quite simple. The call in Julia is `write`. For example, the script `tutorial_simulation.jl` saved the response variable `ybed` to the desktop in binary format by calling\n",
    "\n",
    "    ypath     = expanduser(\"~/Desktop/y.bin\") # path to save response ybed to desktop\n",
    "    write(open(ypath, \"w\"), ybed)             # \"w\"rite ybed to file\n",
    " \n",
    "The script also generated the correct filepaths to simulated genotype data stored the PLINK.jl module. Now let us run the crossvalidation routine with binary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invoking transpose with outfile /Users/kkeys/Desktop/tbed_4.bed\n",
      "Invoking transpose with outfile /Users/kkeys/Desktop/tbed_2.bed\n",
      "Invoking transpose with outfile /Users/kkeys/Desktop/tbed_5.bed\n",
      "Invoking transpose with outfile /Users/kkeys/Desktop/tbed_6.bed\n",
      "Invoking transpose with outfile /Users/kkeys/Desktop/tbed_3.bed\n",
      "Invoking transpose with outfile /Users/kkeys/Desktop/tbed_1.bed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "An IHTCrossvalidationResults object with the following results:\n",
       "Minimum MSE 0.006067673766979373 occurs at k = 10.\n",
       "Best model β has the following nonzero coefficients:\n",
       "10×2 DataFrames.DataFrame\n",
       "│ Row │ Predictor │ β         │\n",
       "├─────┼───────────┼───────────┤\n",
       "│ 1   │ 650       │ -0.179729 │\n",
       "│ 2   │ 3288      │ 1.804     │\n",
       "│ 3   │ 6035      │ 0.137926  │\n",
       "│ 4   │ 6931      │ -0.854346 │\n",
       "│ 5   │ 7949      │ 1.02459   │\n",
       "│ 6   │ 8886      │ 0.0930185 │\n",
       "│ 7   │ 14799     │ -0.439675 │\n",
       "│ 8   │ 14984     │ -1.46289  │\n",
       "│ 9   │ 19620     │ 0.705787  │\n",
       "│ 10  │ 19872     │ 0.0109802 │\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(2016) # reset seed before crossvalidation to make reproducible results\n",
    "cv_bed  = cv_iht(xpath, covpath, ypath, pathidx, folds, nfolds, pids=pids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that IHT finds the correct model size. We can verify that IHT also captures the correct predictors and provides reasonably accurate estimates of the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x2 Array{Int64,2}:\n",
       "   650    650\n",
       "  3288   3288\n",
       "  6035   6035\n",
       "  6931   6931\n",
       "  7949   7949\n",
       "  8886   8886\n",
       " 14799  14799\n",
       " 14984  14984\n",
       " 19620  19620\n",
       " 19872  19872"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10x2 Array{Float64,2}:\n",
       " -0.176622   -0.179729 \n",
       "  1.80336     1.804    \n",
       "  0.135377    0.137926 \n",
       " -0.85557    -0.854346 \n",
       "  1.022       1.02459  \n",
       "  0.0903269   0.0930185\n",
       " -0.442234   -0.439675 \n",
       " -1.46398    -1.46289  \n",
       "  0.705111    0.705787 \n",
       "  0.0109637   0.0109802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display([bidxbed cv_bed.bidx])    # compare the indices\n",
    "display([bbed[bidxbed] cv_bed.b]) # compare the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs\n",
    "\n",
    "As mentioned before, IHT.jl can use GPUs to accelerate computations. This is an advanced topic, so we will only outline its use. We will not execute any code here since we cannot assume that the user has a dedicated GPU on their machine.\n",
    "\n",
    "Using GPUs with IHT.jl require both a `BEDFile` object and a filepath to the GPU kernels. The GPU kernels ship with the PLINK.jl package in the package subdirectory `/src/kernels`. Assuming that a suitable GPU device is available on the machine, one can call `L0_reg` with GPU facilities using\n",
    "\n",
    "    kernfile = open(readall, expanduser(\"~/.julia/v0.4/PLINK/src/kernels/iht_kernels64.cl\")) # read Float64 kernels\n",
    "    output   = L0_reg(xbed, ybed, k, kernfile) # use GPU for L0_reg\n",
    "\n",
    "The previous code creates a long string object called `kernfile` that contains all of the OpenCL kernel code for the GPU.\n",
    "It then calls `L0_reg` with a GPU.\n",
    "\n",
    "Using GPUs in crossvalidation merely entails adding a `kernfile` argument to `cv_iht` between the `path` and `folds` argument. More explicitly, the GPU call is\n",
    "\n",
    "    cv_bed = cv_iht(xpath, covpath, ypath, pathidx, kernfile, folds, pids=pids, nfolds)\n",
    "\n",
    "Before we close, we must remove the GWAS response located at `ypath = ~/Desktop/y.bin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm(ypath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope that this tutorial is useful. Interested readers can consult the following references for further study:\n",
    "\n",
    "- Kevin L. Keys, Gary K. Chen, Kenneth Lange. (2016) *Iterative Hard Thresholding for Model Selection in Genome-Wide Association Studies*. [(arXiv)](http://arxiv.org/abs/1608.01398)\n",
    "- Thomas Blumensath and Mike E. Davies. (2010) \"Normalized Iterative Hard Thresholding: Guaranteed Stability and Performance\". *IEEE Journal of Selected Topics in Signal Processing* **4**:2, 298-309. [(pdf)](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5419091) [(preprint)](http://www.personal.soton.ac.uk/tb1m08/papers/BD_NIHT09.pdf)\n",
    "- Thomas Blumensath and Mike E. Davies. (2009) \"Iterative Hard Thresholding for Compressed Sensing\". *Applied and Computational Harmonic Analysis* **27**:3, 265-274. [(pdf)](http://www.sciencedirect.com/science/article/pii/S1063520309000384) [(arXiv)](http://arxiv.org/abs/0805.0510)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.3",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
