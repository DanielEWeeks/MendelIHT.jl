{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting started\n",
    "\n",
    "In this section, we outline the basic procedure to analyze your GWAS data with MendelIHT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "`MendelIHT.jl` have been tested on Julia 1.0 and 1.2 for Mac, Linus, and windows. A few features are disabled for windows users, and users will be warned when trying to use them.\n",
    "\n",
    "Press `]` to enter package manager mode and type the following (after `pkg>`):\n",
    "```\n",
    "(v1.0) pkg> add https://github.com/OpenMendel/SnpArrays.jl\n",
    "(v1.0) pkg> add https://github.com/OpenMendel/MendelSearch.jl\n",
    "(v1.0) pkg> add https://github.com/OpenMendel/MendelBase.jl\n",
    "(v1.0) pkg> add https://github.com/biona001/MendelIHT.jl\n",
    "```\n",
    "The order of installation is important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Step Workflow\n",
    "\n",
    "Most analysis consists of 3 simple steps:\n",
    "\n",
    "1. Import data.\n",
    "2. Run cross validation: either `cv_iht` or `cv_iht_distribute_folds` to determine best model size.\n",
    "3. Run `L0_reg` to obtain final model.\n",
    "\n",
    "We believe the best way to learn is through examples. Head over to the example section on the left to see these steps in action. Nevertheless, below contains function signatures and use cautions that any users should be aware. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "\n",
    "    (1) `MendelIHT` assumes there are **NO missing genotypes**, and (2) the trios (`.bim`, `.bed`, `.fam`) must all be present in the same directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "\n",
    "A standard analysis runs only 2 functions, other than importing data. For testing small problems (small number of folds), we recommend using `cv_iht`. This function cycles through the testing sets sequentially and fits different sparsity models in parallel. For larger problems where `L0_reg` takes a long time to run, one can instead run `cv_iht_distribute_fold`. This function fits different sparsity models sequentially but initializes all training/testing model in parallel, which consumes more memory (see below). The later strategy allows one to distribute different sparsity parameters to different computers, achieving greater parallel power. \n",
    "\n",
    "```@docs\n",
    "  cv_iht\n",
    "```   \n",
    "\n",
    "```@docs\n",
    "  cv_iht_distribute_fold\n",
    "```   \n",
    "\n",
    "!!! note \n",
    "\n",
    "    **Do not** delete intermediate files with random file names created by `cv_iht` and `cv_iht_distribute_fold` (windows users will be instructed to manually do so via print statements). These are memory-mapped files necessary for cross validation. For `cv_iht`, **you must have `x` GB of free space and RAM on your hard disk** where `x` is your `.bed` file size. For `cv_iht_distribute_fold`, you must have enough RAM and disk space to fit all `q` training datasets simultaneously, each of which typically requires `(q - 1)/q * x` GB. \n",
    "\n",
    "\n",
    "```@docs\n",
    "  L0_reg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Groups and Weights\n",
    "\n",
    "When you have group and weight information, you input them as optional arguments in `L0_reg` and `cv_iht`. The weight vector is a vector of Float64, while the group vector is a vector of integers. For instance,\n",
    "\n",
    "```Julia\n",
    "    g = #import group vector\n",
    "    w = #import weight vector\n",
    "    J = length(unique(g)) # specify number of non-zero groups\n",
    "    result = L0_reg(x, xbm, z, y, J, k, d(), l, group=g, weight=w)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Utilities\n",
    "\n",
    "MendelIHT provides some simulation utilities that help users explore the function and capabilities of iterative hard thresholding. \n",
    "\n",
    "```@docs\n",
    "  simulate_random_snparray\n",
    "```\n",
    "\n",
    "```@docs\n",
    "  simulate_correlated_snparray\n",
    "```\n",
    "\n",
    "!!! note\n",
    "    Simulating a SnpArray with $n$ subjects and $p$ SNPs requires up to $4np$ bits of RAM. Make sure you have enough RAM before simulating very large SnpArrays.\n",
    "\n",
    "```@docs\n",
    "  simulate_random_response\n",
    "```\n",
    "\n",
    "!!! note\n",
    "    For negative binomial and gamma, the link function must be LogLink. For Bernoulli, the probit link seems to work better than logitlink when used in `cv_iht` or `L0_reg`. \n",
    "\n",
    "```@docs\n",
    "  adhoc_add_correlation\n",
    "```\n",
    "\n",
    "```@docs\n",
    "  make_bim_fam_files\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Useful Functions\n",
    "\n",
    "MendelIHT additionally provides useful utilities that may be of interest to a few advanced users. \n",
    "\n",
    "```@docs\n",
    "  iht_run_many_models\n",
    "```\n",
    "\n",
    "```@docs\n",
    "  loglikelihood\n",
    "```\n",
    "\n",
    "```@docs\n",
    "  project_k!\n",
    "```\n",
    "\n",
    "```@docs\n",
    "  project_group_sparse!\n",
    "```\n",
    "\n",
    "```@docs\n",
    "  maf_weights\n",
    "```\n",
    "\n",
    "```@docs\n",
    "  naive_impute\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
