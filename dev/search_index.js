var documenterSearchIndex = {"docs":
[{"location":"man/contributing/#Contributing-1","page":"Contributing","title":"Contributing","text":"","category":"section"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"I am one developer. We are a community. ","category":"page"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"If you would like to contribute to this project, we compiled a list of desired features for this project. Developers of any level is welcomed. Do not be shy because it can't hurt to ask. ","category":"page"},{"location":"man/contributing/#Bug-Fixes-and-User-Support-1","page":"Contributing","title":"Bug Fixes & User Support","text":"","category":"section"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"If you encounter a bug or you need some user support, please open a new issue here. If you can, provide the error message and, ideally, a reproducible code that generated the error.","category":"page"},{"location":"man/contributing/#Citation-1","page":"Contributing","title":"Citation","text":"","category":"section"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"If you use MendelIHT.jl in an academic manuscript, please cite:","category":"page"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"Benjamin B. Chu, Kevin L. Keys, Christopher A. German, Hua Zhou, Jin J. Zhou, Janet S. Sinsheimer, Kenneth Lange. Iterative Hard Thresholding in GWAS: Generalized Linear Models, Prior Weights, and Double Sparsity. bioRxiv doi:10.1101/697755","category":"page"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"Bibtex:","category":"page"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"@article{zhou2019openmendel,\n  title={{Iterative Hard Thresholding in GWAS: Generalized Linear Models, Prior Weights, and Double Sparsity}},\n  author={Chu, Benjamin B and Keys, Kevin L and German, Christopher A and Zhou, Hua and Zhou, Jin J and Sinsheimer, Janet S and Lange, Kenneth},\n  journal={BioRxiv},\n  pages={697755v2},\n  year={2019},\n  publisher={Cold Spring Harbor Laboratory}\n}","category":"page"},{"location":"man/contributing/#","page":"Contributing","title":"Contributing","text":"If you could also press star on the upper right hand corner on our github page, that would be very helpful. ","category":"page"},{"location":"man/getting_started/#Getting-started-1","page":"Getting Started","title":"Getting started","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"In this section, we outline the basic procedure to analyze your GWAS data with MendelIHT. ","category":"page"},{"location":"man/getting_started/#Installation-1","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"MendelIHT.jl have been tested on Julia 1.0 and 1.2 for Mac, Linus, and windows. A few features are disabled for windows users, and users will be warned when trying to use them.","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"Press ] to enter package manager mode and type the following (after pkg>):","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"(v1.0) pkg> add https://github.com/OpenMendel/SnpArrays.jl\n(v1.0) pkg> add https://github.com/OpenMendel/MendelSearch.jl\n(v1.0) pkg> add https://github.com/OpenMendel/MendelBase.jl\n(v1.0) pkg> add https://github.com/biona001/MendelIHT.jl","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"The order of installation is important!","category":"page"},{"location":"man/getting_started/#Step-Workflow-1","page":"Getting Started","title":"3 Step Workflow","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"Most analysis consists of 3 simple steps:","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"Import data.\nRun cross validation: either cv_iht or cv_iht_distribute_folds to determine best model size.\nRun L0_reg to obtain final model.","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"We believe the best way to learn is through examples. Head over to the example section on the left to see these steps in action. Nevertheless, below contains function signatures and use cautions that any users should be aware. ","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"note: Note\n(1) MendelIHT assumes there are NO missing genotypes, and (2) the trios (.bim, .bed, .fam) must all be present in the same directory. ","category":"page"},{"location":"man/getting_started/#Core-Functions-1","page":"Getting Started","title":"Core Functions","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"A standard analysis runs only 2 functions, other than importing data. For testing small problems (small number of folds), we recommend using cv_iht. This function cycles through the testing sets sequentially and fits different sparsity models in parallel. For larger problems where L0_reg takes a long time to run, one can instead run cv_iht_distribute_fold. This function fits different sparsity models sequentially but initializes all training/testing model in parallel, which consumes more memory (see below). The later strategy allows one to distribute different sparsity parameters to different computers, achieving greater parallel power. ","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  cv_iht","category":"page"},{"location":"man/getting_started/#MendelIHT.cv_iht","page":"Getting Started","title":"MendelIHT.cv_iht","text":"cv_iht(d, l, x, z, y, J, path, q)\n\nFor each model specified in path, performs q-fold cross validation and  returns the (averaged) deviance residuals. \n\nThe purpose of this function is to find the best sparsity level k, obtained from selecting the model with the minimum out-of-sample error. Different cross validation folds are cycled through sequentially different paths are fitted in parallel on different CPUs. For doubly sprase projections, no routines exist  to cross validate different group sizes yet. \n\nWarning\n\nDo not remove files with random file names when you run this function. There are  memory mapped files that will be deleted automatically once they are no longer needed.\n\nArguments\n\nd: A distribution (e.g. Normal, Bernoulli)\nl: A link function (e.g. Loglink, ProbitLink)\nx: A SnpArray, which can be memory mapped to a file. Does not engage in any linear algebra\nz: Matrix of non-genetic covariates. The first column usually denotes the intercept. \ny: Response vector\nJ: The number of maximum groups (set as 1 if no group infomation available)\npath: Vector storing different model sizes\nq: Number of cross validation folds. For large data do not set this to be greater than 5\n\nOptional Arguments:\n\nest_r Symbol for whether to estimate nuisance parameters. Only supported distribution is negative binomial and choices include :Newton or :MM.\ngroup vector storing group membership\nweight vector storing vector of weights containing prior knowledge on each SNP\nfolds: Vector that separates the sample into q disjoint subsets\ndestin: Directory where intermediate files will be generated. Directory name must end with /.\ninit: Boolean indicating whether we should initialize IHT algorithm at a good starting guess\nuse_maf: Boolean indicating we should scale the projection step by a weight vector \ndebias: Boolean indicating whether we should debias at each IHT step\nverbose: Whether we want IHT to print meaningful intermediate steps\nparallel: Whether we want to run cv_iht using multiple CPUs (highly recommended)\n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  cv_iht_distribute_fold","category":"page"},{"location":"man/getting_started/#MendelIHT.cv_iht_distribute_fold","page":"Getting Started","title":"MendelIHT.cv_iht_distribute_fold","text":"Performs q-fold cross validation for Iterative hard thresholding to  determine the best model size k. The function is the same as cv_iht  except here each fold is distributed to a different CPU as opposed  to each path to a different CPU. \n\nThis function has the edge over cv_iht because one can fit different  sparsity levels on different computers. But this is assuming you have  enough RAM and disk space to store all training data simultaneously.\n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"note: Note\nDo not delete intermediate files with random file names created by cv_iht and cv_iht_distribute_fold (windows users will be instructed to manually do so via print statements). These are memory-mapped files necessary for cross validation. For cv_iht, you must have x GB of free space and RAM on your hard disk where x is your .bed file size. For cv_iht_distribute_fold, you must have enough RAM and disk space to fit all q training datasets simultaneously, each of which typically requires (q - 1)/q * x GB. ","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  L0_reg","category":"page"},{"location":"man/getting_started/#MendelIHT.L0_reg","page":"Getting Started","title":"MendelIHT.L0_reg","text":"L0_reg(x, xbm, z, y, J, k, d, l)\n\nRuns Iterative Hard Thresholding for GWAS data x, response y, and non-genetic covariates z on a specific sparsity parameter k. If k is a constant, then  each group will have the same sparsity level. To run doubly sparse IHT, construct  k to be a vector where k[i] indicates the max number of predictors for group i. \n\nOne needs to construct a SnpBitMatrix type (xbm) before running this function.\n\nArguments:\n\nx: A SnpArray, which can be memory mapped to a file. Does not engage in any linear algebra\nxbm: The bitarray representation of x. This matrix is loaded in RAM and performs linear algebra. It's possible to set scale=false for xbm, especially when rare SNPs exist\nz: Matrix of non-genetic covariates. The first column usually denotes the intercept. \ny: Response vector\nJ: The number of maximum groups (set as 1 if no group infomation available)\nk: Number of non-zero predictors in each group. Can be a constant or a vector. \nd: A distribution (e.g. Normal, Poisson)\nl: A link function (e.g. Loglink, ProbitLink)\n\nOptional Arguments:\n\ngroup vector storing group membership\nweight vector storing vector of weights containing prior knowledge on each SNP\nuse_maf indicates whether we want to scale the projection with minor allele frequencies (see paper)\ndebias is boolean indicating whether we debias at each iteration (see paper)\nverbose boolean indicating whether we want to print results if model does not converge. Should set to false for multithread/multicore computing\ninit boolean indicating whether we want to initialize β to sensible values through fitting. This is not efficient yet. \ntol is used to track convergence\nmax_iter is the maximum IHT iteration for a model to converge. Defaults to 200, or 100 for cross validation\nmax_step is the maximum number of backtracking. Since l0 norm is not convex, we have no ascent guarantee\n\n\n\n\n\nL0_reg(x, z, y, J, k, d, l)\n\nIHT algorithm that works on general matrices. \n\nArguments\n\nx: A general matrix. User should standardize it first. \nz: Other covariates. The column of intercept should go here.\ny: Response vector\nJ: The number of maximum groups (set as 1 if no group infomation available)\nk: Number of non-zero predictors in each group. Can be an integer or a vector. \nd: A distribution (e.g. Normal, Poisson)\nl: A link function (e.g. Loglink, ProbitLink)\n\nOptional Arguments\n\nOptional arguments are the same as the L0_reg that works on SnpArrays.\n\n\n\n\n\nL0_reg(x, xbm, z, y, J, k, d, l, est_r)\n\nEstimates the nuisance parameter in addition to estimating the mean using IHT. \n\nWe alternate between estimating the mean using IHT and estimating the nuisance parameter using maximum loglikelihood. Currently, only negative binomial regression supports estimating  nuisance paramter, and the method of choice includes Newton or MM. This can be specified with est_r = :MM or est_r = :Newton.\n\nNote: Convergence criteria does not track the r paramter. \n\n\n\n\n\nL0_reg(x, z, y, J, k, d, l, est_r)\n\nEstimates the nuisance parameter in addition to estimating the mean using IHT. x is a  matrix of Float32 or Float64.\n\nWe alternate between estimating the mean using IHT and estimating the nuisance parameter using maximum loglikelihood. Currently, only negative binomial regression supports estimating  nuisance paramter, and the method of choice includes Newton or MM. This can be specified with est_r = :MM or est_r = :Newton.\n\nNote: Convergence criteria does not track the r paramter. \n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#Supported-GLM-models-and-Link-functions-1","page":"Getting Started","title":"Supported GLM models and Link functions","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"MendelIHT borrows distribution and link functions implementationed in GLM.jl and Distributions.jl","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"Distributions (listed with their canonical link) that work with L0_reg and cv_iht are:","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"          Normal (IdentityLink)\n       Bernoulli (LogitLink)\n         Poisson (LogLink)\nNegativeBinomial (LogLink)\n           Gamma (InverseLink) **(not tested)**\n InverseGaussian (InverseSquareLink) **(not tested)**","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"Examples of these distributions in their default value (code from this post):","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"using Distributions, PyPlot\nfigure(figsize=(6,5))\ndfxs = [Bernoulli(),Gamma(),InverseGaussian(),NegativeBinomial(),Normal(),Poisson()]\ndnames = [\"Bernoulli\",\"Gamma\",\"InverseGaussian\",\"NegativeBinomial\",\"Normal\",\"Poisson\"]\nfor i in 1:length(dfxs)\n    subplot(7,1,i); subplots_adjust(hspace=0)\n    PyPlot.plt.hist(rand(dfxs[i], 100000),-7.5:0.1:7.5,align=\"left\",label=\"x\");xticks(-8:8)\n    ax= gca()\n    ax.yaxis.set_visible(false);ax.spines[\"left\"].set_visible(false);ax.spines[\"right\"].set_visible(false);ax.spines[\"top\"].set_visible(false)\n    i !== length(dfxs) && ax.xaxis.set_visible(false);annotate(dnames[i],xy=[0,0.5],xycoords=\"axes fraction\",ha=\"right\",va=\"center\")\nend","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"(Image: png)","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"Available link functions are:","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"CauchitLink\nCloglogLink\nIdentityLink\nInverseLink\nInverseSquareLink\nLogitLink\nLogLink\nProbitLink\nSqrtLink","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"tip: Tip\nFor logistic regression, the ProbitLink seems to work better than LogitLink. For d = NegativeBinomial or d=Gamma, the link function must be LogLink. ","category":"page"},{"location":"man/getting_started/#Specifying-Groups-and-Weights-1","page":"Getting Started","title":"Specifying Groups and Weights","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"When you have group and weight information, you input them as optional arguments in L0_reg and cv_iht. The weight vector is a vector of Float64, while the group vector is a vector of integers. For instance,","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"    g = #import group vector\n    w = #import weight vector\n    J = length(unique(g)) # specify number of non-zero groups\n    result = L0_reg(x, xbm, z, y, J, k, d(), l, group=g, weight=w)","category":"page"},{"location":"man/getting_started/#Simulation-Utilities-1","page":"Getting Started","title":"Simulation Utilities","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"MendelIHT provides some simulation utilities that help users explore the function and capabilities of iterative hard thresholding. ","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  simulate_random_snparray","category":"page"},{"location":"man/getting_started/#MendelIHT.simulate_random_snparray","page":"Getting Started","title":"MendelIHT.simulate_random_snparray","text":"simulate_random_snparray(n::Integer, p::Integer, s::String; mafs::Vector{Float64}, min_ma::Integer)\n\nCreates a random SnpArray in the current directory without missing value,  where each SNP has ⫺5 (default) minor alleles. \n\nNote: if supplied minor allele frequency is extremely small, it could take a long time for  the simulation to generate samples where at least min_ma (defaults to 5) are present. \n\nArguments:\n\nn: number of samples\np: number of SNPs\ns: name of SnpArray that will be created (memory mapped) in the current directory. To not memory map, use undef.\n\nOptional Arguments:\n\nmafs: vector of desired minor allele freuqencies (uniform(0, 0.5) by default)\nmin_ma: the minimum number of minor alleles that must be present for each SNP (defaults to 5)\n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  simulate_correlated_snparray","category":"page"},{"location":"man/getting_started/#MendelIHT.simulate_correlated_snparray","page":"Getting Started","title":"MendelIHT.simulate_correlated_snparray","text":"simulate_correlated_snparray(n, p, s; block_length, hap, prob)\n\nSimulates a SnpArray with correlation. SNPs are divided into blocks where each adjacent SNP is the same with probability prob. There are no correlation between blocks.\n\nArguments:\n\nn: number of samples\np: number of SNPs\ns: name of SnpArray that will be created (memory mapped) in the current directory. To not memory map, use undef.\n\nOptional arguments:\n\nblock_length: length of each LD block\nhap: number of haplotypes to simulate for each block\nprob: with probability prob an adjacent SNP would be the same. \n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"note: Note\nSimulating a SnpArray with n subjects and p SNPs requires up to 4np bits of RAM. Make sure you have enough RAM before simulating very large SnpArrays.","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  simulate_random_response","category":"page"},{"location":"man/getting_started/#MendelIHT.simulate_random_response","page":"Getting Started","title":"MendelIHT.simulate_random_response","text":"simulate_random_response(x::SnpArray, xbm::SnpBitMatrix, k::Int, d::UnionAll, l::Link)\n\nThis function simulates a random response (trait) vector y based on provided x, β, distirbution, and link function. When the distribution is from Poisson, Gamma, or Negative Binomial, we simulate β ∼ N(0, 0.3)  to roughly ensure the mean of response y doesn't become too large. For other distributions, we choose β ∼ N(0, 1). \n\nArguments\n\nx: The SnpArray\nxbm: SnpBitMatrix type of your SnpArray\nk: the true number of predictors. \nd: The distribution of the simulated trait (note typeof(d) = UnionAll but typeof(d()) is an actual distribution: e.g. Normal)\nl: The link function. Input canonicallink(d()) if you want to use the canonical link of d.\n\nOptional arguments\n\nr: The number of success until stopping in negative binomial regression, defaults to 10\nα: Shape parameter of the gamma distribution, defaults to 1\n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"note: Note\nFor negative binomial and gamma, the link function must be LogLink. For Bernoulli, the probit link seems to work better than logitlink when used in cv_iht or L0_reg. ","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  adhoc_add_correlation","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  make_bim_fam_files","category":"page"},{"location":"man/getting_started/#MendelIHT.make_bim_fam_files","page":"Getting Started","title":"MendelIHT.make_bim_fam_files","text":"make_bim_fam_files(x::SnpArray, y, name::String)\n\nCreates .bim and .bed files from a SnpArray. \n\nArguments:\n\nx: A SnpArray (i.e. .bed file on the disk) for which you wish to create corresponding .bim and .fam files.\nname: string that should match the .bed file (Do not include .bim or .fam extensions in name).\ny: Trait vector that will go in to the 6th column of .fam file. \n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#Other-Useful-Functions-1","page":"Getting Started","title":"Other Useful Functions","text":"","category":"section"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"MendelIHT additionally provides useful utilities that may be of interest to a few advanced users. ","category":"page"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  iht_run_many_models","category":"page"},{"location":"man/getting_started/#MendelIHT.iht_run_many_models","page":"Getting Started","title":"MendelIHT.iht_run_many_models","text":"Runs IHT across many different model sizes specifed in path.  This is basically the same as cv_iht except we DO NOT validate each model  in a holdout set, meaning that this will definitely induce overfitting as we increase model size. Use this to perform a quick estimate a range of feasible model sizes before  engaging in full cross validation. \n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  loglikelihood","category":"page"},{"location":"man/getting_started/#MendelIHT.loglikelihood","page":"Getting Started","title":"MendelIHT.loglikelihood","text":"loglikelihood(d::UnivariateDistribution, y::AbstractVector, μ::AbstractVector)\n\nCalculates the loglikelihood of observing y given mean μ and some distribution  d. \n\nNote that loglikelihood is the sum of the logpdfs for each observation.  For each logpdf from Normal, Gamma, and InverseGaussian, we scale by dispersion. \n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  project_k!","category":"page"},{"location":"man/getting_started/#MendelIHT.project_k!","page":"Getting Started","title":"MendelIHT.project_k!","text":"project_k!(x::AbstractVector, k::Integer)\n\nSets all but the largest k entries of x to 0. \n\nExamples:\n\nusing MendelIHT\nx = [1.0; 2.0; 3.0]\nproject_k!(x, 2) # keep 2 largest entry\njulia> x\n3-element Array{Float64,1}:\n 0.0\n 2.0\n 3.0\n\nArguments:\n\nx: the vector to project.\nk: the number of components of x to preserve.\n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  project_group_sparse!","category":"page"},{"location":"man/getting_started/#MendelIHT.project_group_sparse!","page":"Getting Started","title":"MendelIHT.project_group_sparse!","text":"project_group_sparse!(y::AbstractVector, group::AbstractVector, J::Integer, k<:Real)\n\nWhen k is an integer, projects the vector y onto the set with at most J active groups  and at most k active predictors per group. To have variable group sparsity level, input k as a vector of integers. We will preserve k[1] elements for group 1, k[2] predictors for  group 2...etc. This function assumes there are no unknown or overlaping group membership.\n\nNote: In the group vector, the first group must be 1, and the second group must be 2...etc. \n\nExamples\n\nusing MendelIHT\nJ, k, n = 2, 3, 20\ny = collect(1.0:20.0)\ny_copy = copy(y)\ngroup = rand(1:5, n)\nproject_group_sparse!(y, group, J, k)\nfor i = 1:length(y)\n    println(i,\"  \",group[i],\"  \",y[i],\"  \",y_copy[i])\nend\n\nJ, k, n = 2, 0.9, 20\ny = collect(1.0:20.0)\ny_copy = copy(y)\ngroup = rand(1:5, n)\nproject_group_sparse!(y, group, J, k)\nfor i = 1:length(y)\n    println(i,\"  \",group[i],\"  \",y[i],\"  \",y_copy[i])\nend\n\nArguments\n\ny: The vector to project\ngroup: Vector encoding group membership\nJ: Max number of non-zero group\nk: Maximum predictors per group. Can be a positive integer or a vector of integers. \n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  maf_weights","category":"page"},{"location":"man/getting_started/#MendelIHT.maf_weights","page":"Getting Started","title":"MendelIHT.maf_weights","text":"maf_weights(x::SnpArray; max_weight::T = Inf)\n\nCalculates the prior weight based on minor allele frequencies. \n\nReturns an array of weights where w[i] = 1 / (2 * sqrt(p[i] (1 - p[i]))) ∈ (1, ∞). Here p is the minor allele frequency computed by maf() in SnpArrays. \n\nx: A SnpArray \nmax_weight: Maximum weight for any predictor. Defaults to Inf. \n\n\n\n\n\n","category":"function"},{"location":"man/getting_started/#","page":"Getting Started","title":"Getting Started","text":"  naive_impute","category":"page"},{"location":"man/getting_started/#MendelIHT.naive_impute","page":"Getting Started","title":"MendelIHT.naive_impute","text":"naive_impute(x, destination)\n\nImputes missing entries of a SnpArray using the mode of each SNP, and saves the result in a new file called destination in current directory.  Non-missing entries are the same. \n\n\n\n\n\n","category":"function"},{"location":"man/examples/#Examples-1","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Here we give numerous example analysis of GWAS data with MendelIHT. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# machine information for reproducibility\nversioninfo()","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Julia Version 1.0.3\nCommit 099e826241 (2018-12-18 01:34 UTC)\nPlatform Info:\n  OS: macOS (x86_64-apple-darwin14.5.0)\n  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"#first add workers needed for parallel computing. Add only as many CPU cores available\nusing Distributed\naddprocs(4)\n\n#load necessary packages for running all examples below\nusing MendelIHT\nusing SnpArrays\nusing DataFrames\nusing Distributions\nusing Random\nusing LinearAlgebra\nusing GLM\nusing DelimitedFiles\nusing Statistics\nusing BenchmarkTools","category":"page"},{"location":"man/examples/#Example-1:-How-to-Import-Data-1","page":"Examples","title":"Example 1: How to Import Data","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"We use SnpArrays.jl as backend to process genotype files. Internally, the genotype file is a memory mapped SnpArray, which will not be loaded into RAM. If you wish to run L0_reg, you need to convert a SnpArray into a SnpBitMatrix, which consumes n times p times 2 bits of RAM. Non-genetic predictors should be read into Julia in the standard way, and should be stored as an Array{Float64, 2}. One should include the intercept (typically in the first column), but an intercept is not required to run IHT. ","category":"page"},{"location":"man/examples/#Simulate-example-data-(to-be-imported-later)-1","page":"Examples","title":"Simulate example data (to be imported later)","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"First we simulate an example PLINK trio (.bim, .bed, .fam) and non-genetic covariates, then we illustrate how to import them. For genotype matrix simulation, we simulate under the model:","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"x_ij sim rm Binomial(2 rho_j)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"rho_j sim rm Uniform(0 05)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# rows and columns\nn = 1000\np = 10000\n\n#random seed\nRandom.seed!(1111)\n\n# simulate random `.bed` file\nx = simulate_random_snparray(n, p, \"example.bed\")\n\n# create accompanying `.bim`, `.fam` files (randomly generated)\nmake_bim_fam_files(x, ones(n), \"example\")\n\n# simulate non-genetic covariates (in this case, we include intercept and sex)\nz = [ones(n, 1) rand(0:1, n)]\nwritedlm(\"example_nongenetic_covariates.txt\", z)","category":"page"},{"location":"man/examples/#Reading-Genotype-data-and-Non-Genetic-Covariates-from-disk-1","page":"Examples","title":"Reading Genotype data and Non-Genetic Covariates from disk","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"x = SnpArray(\"example.bed\")\nz = readdlm(\"example_nongenetic_covariates.txt\")","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"1000×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  0.0\n 1.0  0.0\n 1.0  1.0\n 1.0  0.0\n 1.0  0.0\n 1.0  1.0\n 1.0  0.0\n 1.0  1.0\n 1.0  1.0\n 1.0  0.0\n 1.0  0.0\n 1.0  1.0\n ⋮       \n 1.0  0.0\n 1.0  1.0\n 1.0  0.0\n 1.0  0.0\n 1.0  0.0\n 1.0  0.0\n 1.0  0.0\n 1.0  0.0\n 1.0  0.0\n 1.0  0.0\n 1.0  1.0\n 1.0  0.0","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"note: Note\n(1) MendelIHT.jl assumes there are NO missing genotypes, (2) 1 always encode the minor allele, and (3) the trios (.bim, .bed, .fam) are all be present in the same directory. ","category":"page"},{"location":"man/examples/#Standardizing-Non-Genetic-Covariates.-1","page":"Examples","title":"Standardizing Non-Genetic Covariates.","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"We recommend standardizing all genetic and non-genetic covarariates (including binary and categorical), except for the intercept. This ensures equal penalization for all predictors. For genotype matrix, SnpBitMatrix efficiently achieves this standardization. For non-genetic covariates, we use the built-in function standardize!. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# SnpBitMatrix can automatically standardizes .bed file (without extra memory) and behaves like a matrix\nxbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n\n# using view is important for correctness\nstandardize!(@view(z[:, 2:end])) \nz","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"1000×2 Array{Float64,2}:\n 1.0   1.0015  \n 1.0  -0.997503\n 1.0  -0.997503\n 1.0   1.0015  \n 1.0  -0.997503\n 1.0  -0.997503\n 1.0   1.0015  \n 1.0  -0.997503\n 1.0   1.0015  \n 1.0   1.0015  \n 1.0  -0.997503\n 1.0  -0.997503\n 1.0   1.0015  \n ⋮             \n 1.0  -0.997503\n 1.0   1.0015  \n 1.0  -0.997503\n 1.0  -0.997503\n 1.0  -0.997503\n 1.0  -0.997503\n 1.0  -0.997503\n 1.0  -0.997503\n 1.0  -0.997503\n 1.0  -0.997503\n 1.0   1.0015  \n 1.0  -0.997503","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# remove simulated data once they are no longer needed\nrm(\"example.bed\", force=true)\nrm(\"example.bim\", force=true)\nrm(\"example.fam\", force=true)\nrm(\"example_nongenetic_covariates.txt\", force=true)","category":"page"},{"location":"man/examples/#Example-2:-Running-IHT-on-Quantitative-Traits-1","page":"Examples","title":"Example 2: Running IHT on Quantitative Traits","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Quantitative traits are continuous phenotypes whose distribution can be modeled by the normal distribution. Then using the genotype matrix mathbfX and phenotype vector mathbfy, we want to recover beta such that mathbfy approx mathbfXbeta. In this example, we assume we know the true sparsity level k. ","category":"page"},{"location":"man/examples/#Step-1:-Import-data-1","page":"Examples","title":"Step 1: Import data","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"In Example 1 we illustrated how to import data into Julia. So here we use simulated data (code) because, only then, can we compare IHT's result to the true solution. Below we simulate a GWAS data with n=1000 patients and p=10000 SNPs. Here the quantitative trait vector are affected by k = 10 causal SNPs, with no non-genetic confounders. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"In this example, our model is simulated as:","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"y_i sim mathbfx_i^Tmathbfbeta + epsilon_i","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"x_ij sim rm Binomial(2 rho_j)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"rho_j sim rm Uniform(0 05)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"epsilon_i sim rm N(0 1)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"beta_i sim rm N(0 1)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# Define model dimensions, true model size, distribution, and link functions\nn = 1000\np = 10000\nk = 10\nd = Normal\nl = canonicallink(d())\n\n# set random seed for reproducibility\nRandom.seed!(2019) \n\n# simulate SNP matrix, store the result in a file called tmp.bed\nx = simulate_random_snparray(n, p, \"tmp.bed\")\n\n#construct the SnpBitMatrix type (needed for L0_reg() and simulate_random_response() below)\nxbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true); \n\n# intercept is the only nongenetic covariate\nz = ones(n, 1) \n\n# simulate response y, true model b, and the correct non-0 positions of b\ny, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);","category":"page"},{"location":"man/examples/#Step-2:-Run-cross-validation-to-determine-best-model-size-1","page":"Examples","title":"Step 2: Run cross validation to determine best model size","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"To run cv_iht, you must specify path and num_fold, defined below:","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"path are all the model sizes you wish to test, stored in a vector of integers.\nnum_fold indicates how many disjoint partitions of the samples is requested. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"By default, we partition the training/testing data randomly, but you can change this by inputing the fold vector as optional argument. In this example we tested k = 1 2  20 across 3 fold cross validation. This is equivalent to running IHT across 60 different models, and hence, is ideal for parallel computing (which you specify by parallel=true). ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"path = collect(1:20)\nnum_folds = 3\nmses = cv_iht(d(), l, x, z, y, 1, path, num_folds, parallel=true); #here 1 is for number of groups","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Crossvalidation Results:\n\tk\tMSE\n\t1\t1927.0765190526674\n\t2\t1443.8788742220863\n\t3\t1080.041135323195\n\t4\t862.2385953735204\n\t5\t705.1014346627649\n\t6\t507.3949359364219\n\t7\t391.96868764622843\n\t8\t368.45440222003174\n\t9\t350.642794092518\n\t10\t345.8380848576577\n\t11\t350.5188147284578\n\t12\t359.42391568519577\n\t13\t363.70956969599075\n\t14\t377.30732985896975\n\t15\t381.0310879522694\n\t16\t392.56439238382615\n\t17\t396.81166049333797\n\t18\t397.3010019298764\n\t19\t406.47023764639624\n\t20\t410.4672260807978","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"note: Note\nDO NOT remove intermediate files with random filenames as generated by cv_iht(). These are necessary auxiliary files that will be automatically removed when cross validation completes. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"tip: Tip\nBecause Julia employs a JIT compiler, the first round of any function call run will always take longer and consume extra memory. Therefore it is advised to always run a small \"test example\" (such as this one!) before running cross validation on a large dataset. ","category":"page"},{"location":"man/examples/#Step-3:-Run-full-model-on-the-best-estimated-model-size-1","page":"Examples","title":"Step 3: Run full model on the best estimated model size","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"cv_iht finished in less than a minute. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"According to our cross validation result, the best model size that minimizes deviance residuals (i.e. MSE on the q-th subset of samples) is attained at k = 10. That is, cross validation detected that we need 10 SNPs to achieve the best model size. Using this information, one can re-run the IHT algorithm on the full dataset to obtain the best estimated model.","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"k_est = argmin(mses)\nresult = L0_reg(x, xbm, z, y, 1, k_est, d(), l) ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"IHT estimated 10 nonzero SNP predictors and 0 non-genetic predictors.\n\nCompute time (sec):     0.4135408401489258\nFinal loglikelihood:    -1406.8807653835697\nIterations:             6\n\nSelected genetic predictors:\n10×2 DataFrame\n│ Row │ Position │ Estimated_β │\n│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n├─────┼──────────┼─────────────┤\n│ 1   │ 853      │ -1.24117    │\n│ 2   │ 877      │ -0.234676   │\n│ 3   │ 924      │ 0.82014     │\n│ 4   │ 2703     │ 0.583403    │\n│ 5   │ 4241     │ 0.298304    │\n│ 6   │ 4783     │ -1.14459    │\n│ 7   │ 5094     │ 0.673012    │\n│ 8   │ 5284     │ -0.709736   │\n│ 9   │ 7760     │ 0.16866     │\n│ 10  │ 8255     │ 1.08117     │\n\nSelected nongenetic predictors:\n0×2 DataFrame","category":"page"},{"location":"man/examples/#Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-1","page":"Examples","title":"Step 4 (only for simulated data): Check final model against simulation","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Since all our data and model was simulated, we can see how well cv_iht combined with L0_reg estimated the true model. For this example, we find that IHT found every simulated predictor, with 0 false positives. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model = DataFrame(\n    true_β      = true_b[correct_position], \n    estimated_β = result.beta[correct_position])\n@show compare_model\n\n#clean up. Windows user must do this step manually (outside notebook/REPL)\nrm(\"tmp.bed\", force=true)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model = 10×2 DataFrame\n│ Row │ true_β   │ estimated_β │\n│     │ Float64  │ Float64     │\n├─────┼──────────┼─────────────┤\n│ 1   │ -1.29964 │ -1.24117    │\n│ 2   │ -0.2177  │ -0.234676   │\n│ 3   │ 0.786217 │ 0.82014     │\n│ 4   │ 0.599233 │ 0.583403    │\n│ 5   │ 0.283711 │ 0.298304    │\n│ 6   │ -1.12537 │ -1.14459    │\n│ 7   │ 0.693374 │ 0.673012    │\n│ 8   │ -0.67709 │ -0.709736   │\n│ 9   │ 0.14727  │ 0.16866     │\n│ 10  │ 1.03477  │ 1.08117     │","category":"page"},{"location":"man/examples/#Example-3:-Logistic-Regression-Controlling-for-Sex-1","page":"Examples","title":"Example 3: Logistic Regression Controlling for Sex","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"We show how to use IHT to handle case-control studies, while handling non-genetic covariates. In this example, we fit a logistic regression model with IHT using simulated case-control data, while controling for sex as a nongenetic covariate. ","category":"page"},{"location":"man/examples/#Step-1:-Import-Data-1","page":"Examples","title":"Step 1: Import Data","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Again we use a simulated model:","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"y_i sim rm Bernoulli(mathbfx_i^Tmathbfbeta)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"x_ij sim rm Binomial(2 rho_j)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"rho_j sim rm Uniform(0 05)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"beta_i sim rm N(0 1)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"beta_rm intercept = 1","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"beta_rm sex = 15","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"We assumed there are k=8 genetic predictors and 2 non-genetic predictors (intercept and sex) that affects the trait. The simulation code in our package does not yet handle simulations with non-genetic predictors, so we must simulate these phenotypes manually. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# Define model dimensions, true model size, distribution, and link functions\nn = 1000\np = 10000\nk = 10\nd = Bernoulli\nl = canonicallink(d())\n\n# set random seed for reproducibility\nRandom.seed!(2019)\n\n# construct SnpArray and SnpBitMatrix\nx = simulate_random_snparray(n, p, \"tmp.bed\")\nxbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n\n# nongenetic covariate: first column is the intercept, second column is sex: 0 = male 1 = female\nz = ones(n, 2) \nz[:, 2] .= rand(0:1, n)\n\n# randomly set genetic predictors\ntrue_b = zeros(p) \ntrue_b[1:k-2] = randn(k-2)\nshuffle!(true_b)\n\n# find correct position of genetic predictors\ncorrect_position = findall(!iszero, true_b)\n\n# define effect size of non-genetic predictors: intercept & sex\ntrue_c = [1.0; 1.5] \n\n# simulate phenotype using genetic and nongenetic predictors\nprob = GLM.linkinv.(l, xbm * true_b .+ z * true_c)\ny = [rand(d(i)) for i in prob]\ny = Float64.(y); # y must be floating point numbers","category":"page"},{"location":"man/examples/#Step-2:-Run-cross-validation-to-determine-best-model-size-2","page":"Examples","title":"Step 2: Run cross validation to determine best model size","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"To run cv_iht, you must specify path and num_fold, defined below:","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"path are all the model sizes you wish to test, stored in a vector of integers.\nnum_fold indicates how many disjoint partitions of the samples is requested. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"By default, we partition the training/testing data randomly, but you can change this by inputing the fold vector as optional argument. In this example we tested k = 1 2  20 across 3 fold cross validation. This is equivalent to running IHT across 60 different models, and hence, is ideal for parallel computing (which you specify by parallel=true). ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"path = collect(1:20)\nnum_folds = 3\nmses = cv_iht(d(), l, x, z, y, 1, path, num_folds, parallel=true); #here 1 is for number of groups","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Crossvalidation Results:\n\tk\tMSE\n\t1\t391.44426892225727\n\t2\t365.7520496496987\n\t3\t332.3801926093215\n\t4\t273.2081512206048\n\t5\t253.31631985207758\n\t6\t234.93701288953315\n\t7\t221.997334181244\n\t8\t199.01688783420346\n\t9\t208.31087723164197\n\t10\t216.00575628120708\n\t11\t227.91834469184545\n\t12\t242.42456871743065\n\t13\t261.46346209331466\n\t14\t263.5229307137862\n\t15\t283.30379378951073\n\t16\t328.2771991160804\n\t17\t290.4512419547228\n\t18\t350.3516280657363\n\t19\t361.61016297810295\n\t20\t418.2370935226805","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"tip: Tip\nIn our experience, using the ProbitLink for logistic regressions deliver better results than LogitLink (which is the canonical link). But of course, one should choose the link that gives the higher loglikelihood. ","category":"page"},{"location":"man/examples/#Step-3:-Run-full-model-on-the-best-estimated-model-size-2","page":"Examples","title":"Step 3: Run full model on the best estimated model size","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"cv_iht finished in about a minute. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Cross validation have declared that k_best = 8. Using this information, one can re-run the IHT algorithm on the full dataset to obtain the best estimated model.","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"k_est = argmin(mses)\nresult = L0_reg(x, xbm, z, y, 1, k_est, d(), l)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"IHT estimated 6 nonzero SNP predictors and 2 non-genetic predictors.\n\nCompute time (sec):     1.6644580364227295\nFinal loglikelihood:    -290.4509381564733\nIterations:             37\n\nSelected genetic predictors:\n6×2 DataFrame\n│ Row │ Position │ Estimated_β │\n│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n├─────┼──────────┼─────────────┤\n│ 1   │ 1152     │ 0.966731    │\n│ 2   │ 1576     │ 1.56183     │\n│ 3   │ 3411     │ 0.87674     │\n│ 4   │ 5765     │ -1.75611    │\n│ 5   │ 5992     │ -2.04506    │\n│ 6   │ 8781     │ 0.760213    │\n\nSelected nongenetic predictors:\n2×2 DataFrame\n│ Row │ Position │ Estimated_β │\n│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n├─────┼──────────┼─────────────┤\n│ 1   │ 1        │ 0.709909    │\n│ 2   │ 2        │ 1.65049     │","category":"page"},{"location":"man/examples/#Step-4-(only-for-simulated-data):-Check-final-model-against-simulation-2","page":"Examples","title":"Step 4 (only for simulated data): Check final model against simulation","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Since all our data and model was simulated, we can see how well cv_iht combined with L0_reg estimated the true model. For this example, we find that IHT found both nongenetic predictor, but missed 2 genetic predictors. The 2 genetic predictors that we missed had much smaller effect size, so given that we only had 1000 samples, this is hardly surprising. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model_genetics = DataFrame(\n    true_β      = true_b[correct_position], \n    estimated_β = result.beta[correct_position])\n\ncompare_model_nongenetics = DataFrame(\n    true_c      = true_c[1:2], \n    estimated_c = result.c[1:2])\n\n@show compare_model_genetics\n@show compare_model_nongenetics\n\n#clean up. Windows user must do this step manually (outside notebook/REPL)\nrm(\"tmp.bed\", force=true)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model_genetics = 8×2 DataFrame\n│ Row │ true_β   │ estimated_β │\n│     │ Float64  │ Float64     │\n├─────┼──────────┼─────────────┤\n│ 1   │ 0.961937 │ 0.966731    │\n│ 2   │ 0.189267 │ 0.0         │\n│ 3   │ 1.74008  │ 1.56183     │\n│ 4   │ 0.879004 │ 0.87674     │\n│ 5   │ 0.213066 │ 0.0         │\n│ 6   │ -1.74663 │ -1.75611    │\n│ 7   │ -1.93402 │ -2.04506    │\n│ 8   │ 0.632786 │ 0.760213    │\ncompare_model_nongenetics = 2×2 DataFrame\n│ Row │ true_c  │ estimated_c │\n│     │ Float64 │ Float64     │\n├─────┼─────────┼─────────────┤\n│ 1   │ 1.0     │ 0.709909    │\n│ 2   │ 1.5     │ 1.65049     │","category":"page"},{"location":"man/examples/#Example-4:-Poisson-Regression-with-Acceleration-(i.e.-debias)-1","page":"Examples","title":"Example 4: Poisson Regression with Acceleration (i.e. debias)","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"In this example, we show how debiasing can potentially achieve dramatic speedup. Our model is:","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"y_i sim rm Poisson(mathbfx_i^T mathbfbeta)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"x_ij sim rm Binomial(2 rho_j)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"rho_j sim rm Uniform(0 05)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"beta_i sim rm N(0 03)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# Define model dimensions, true model size, distribution, and link functions\nn = 1000\np = 10000\nk = 10\nd = Poisson\nl = canonicallink(d())\n\n# set random seed for reproducibility\nRandom.seed!(2019)\n\n# construct SnpArray, SnpBitMatrix, and intercept\nx = simulate_random_snparray(n, p, \"tmp.bed\")\nxbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\nz = ones(n, 1) \n\n# simulate response, true model b, and the correct non-0 positions of b\ny, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);","category":"page"},{"location":"man/examples/#First-Compare-Reconstruction-Result-1","page":"Examples","title":"First Compare Reconstruction Result","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"First we show that, with or without debiasing, we obtain comparable results with L0_reg.","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"no_debias  = L0_reg(x, xbm, z, y, 1, k, d(), l, debias=false)\nyes_debias = L0_reg(x, xbm, z, y, 1, k, d(), l, debias=true);","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model = DataFrame(\n    position    = correct_position,\n    true_β      = true_b[correct_position], \n    no_debias_β = no_debias.beta[correct_position],\n    yes_debias_β = yes_debias.beta[correct_position])\n@show compare_model;","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model = 10×4 DataFrame\n│ Row │ position │ true_β     │ no_debias_β │ yes_debias_β │\n│     │ Int64    │ Float64    │ Float64     │ Float64      │\n├─────┼──────────┼────────────┼─────────────┼──────────────┤\n│ 1   │ 853      │ -0.389892  │ -0.384161   │ -0.38744     │\n│ 2   │ 877      │ -0.0653099 │ 0.0         │ 0.0          │\n│ 3   │ 924      │ 0.235865   │ 0.246213    │ 0.240514     │\n│ 4   │ 2703     │ 0.17977    │ 0.237651    │ 0.225127     │\n│ 5   │ 4241     │ 0.0851134  │ 0.0         │ 0.0894244    │\n│ 6   │ 4783     │ -0.33761   │ -0.300663   │ -0.307515    │\n│ 7   │ 5094     │ 0.208012   │ 0.223384    │ 0.215149     │\n│ 8   │ 5284     │ -0.203127  │ -0.225593   │ -0.209308    │\n│ 9   │ 7760     │ 0.0441809  │ 0.0         │ 0.0          │\n│ 10  │ 8255     │ 0.310431   │ 0.287363    │ 0.301717     │","category":"page"},{"location":"man/examples/#Compare-Speed-and-Memory-Usage-1","page":"Examples","title":"Compare Speed and Memory Usage","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Now we illustrate that debiasing may dramatically reduce computational time (in this case ~50%), at a cost of increasing the memory usage. In practice, this extra memory usage hardly matters because the matrix size will dominate for larger problems. See our paper for complete benchmark figure.","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"@benchmark L0_reg(x, xbm, z, y, 1, k, d(), l, debias=false) seconds=15","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"BenchmarkTools.Trial: \n  memory estimate:  2.16 MiB\n  allocs estimate:  738\n  --------------\n  minimum time:     673.188 ms (0.00% GC)\n  median time:      706.368 ms (0.00% GC)\n  mean time:        708.080 ms (0.04% GC)\n  maximum time:     741.125 ms (0.00% GC)\n  --------------\n  samples:          22\n  evals/sample:     1","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"@benchmark L0_reg(x, xbm, z, y, 1, k, d(), l, debias=true) seconds=15","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"BenchmarkTools.Trial: \n  memory estimate:  2.62 MiB\n  allocs estimate:  1135\n  --------------\n  minimum time:     337.368 ms (0.00% GC)\n  median time:      350.194 ms (0.00% GC)\n  mean time:        349.958 ms (0.10% GC)\n  maximum time:     358.095 ms (0.00% GC)\n  --------------\n  samples:          43\n  evals/sample:     1","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"#clean up. Windows user must do this step manually (outside notebook/REPL)\nrm(\"tmp.bed\", force=true)","category":"page"},{"location":"man/examples/#Example-5:-Negative-Binomial-regression-with-group-information-1","page":"Examples","title":"Example 5: Negative Binomial regression with group information","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"In this example, we show how to include group information to perform doubly sparse projections. Here the final model would contain at most J = 5 groups where each group contains limited number of (prespecified) SNPs. For simplicity, we assume the sparsity parameter k is known. ","category":"page"},{"location":"man/examples/#Data-simulation-1","page":"Examples","title":"Data simulation","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"To illustrate the effect of group information and prior weights, we generated correlated genotype matrix according to the procedure outlined in our paper. In this example, each SNP belongs to 1 of 500 disjoint groups containing 20 SNPs each; j = 5 distinct groups are each assigned 125 causal SNPs with effect sizes randomly chosen from 0202. In all there 15 causal SNPs.  For grouped-IHT, we assume perfect group information. That is, the selected groups containing 1∼5 causative SNPs are assigned maximum within-group sparsity lambda_g = 125. The remaining groups are assigned lambda_g = 1 (i.e. only 1 active predictor are allowed).","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# define problem size\nd = NegativeBinomial\nl = LogLink()\nn = 1000\np = 10000\nblock_size = 20                  #simulation parameter\nnum_blocks = Int(p / block_size) #simulation parameter\n\n# set seed\nRandom.seed!(2019)\n\n# assign group membership\nmembership = collect(1:num_blocks)\ng = zeros(Int64, p + 1)\nfor i in 1:length(membership)\n    for j in 1:block_size\n        cur_row = block_size * (i - 1) + j\n        g[block_size*(i - 1) + j] = membership[i]\n    end\nend\ng[end] = membership[end]\n\n#simulate correlated snparray\nx = simulate_correlated_snparray(n, p, \"tmp.bed\")\nz = ones(n, 1) # the intercept\nx_float = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, center=true, scale=true)\n\n#simulate true model, where 5 groups each with 1~5 snps contribute\ntrue_b = zeros(p)\ntrue_groups = randperm(num_blocks)[1:5]\nsort!(true_groups)\nwithin_group = [randperm(block_size)[1:1], randperm(block_size)[1:2], \n                randperm(block_size)[1:3], randperm(block_size)[1:4], \n                randperm(block_size)[1:5]]\ncorrect_position = zeros(Int64, 15)\nfor i in 1:5\n    cur_group = block_size * (true_groups[i] - 1)\n    cur_group_snps = cur_group .+ within_group[i]\n    start, last = Int(i*(i-1)/2 + 1), Int(i*(i+1)/2)\n    correct_position[start:last] .= cur_group_snps\nend\nfor i in 1:15\n    true_b[correct_position[i]] = rand(-1:2:1) * 0.2\nend\nsort!(correct_position)\n\n# simulate phenotype\nr = 10 #nuisance parameter\nμ = GLM.linkinv.(l, x_float * true_b)\nclamp!(μ, -20, 20)\nprob = 1 ./ (1 .+ μ ./ r)\ny = [rand(d(r, i)) for i in prob] #number of failures before r success occurs\ny = Float64.(y);","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"#run IHT without groups\nk = 15\nungrouped = L0_reg(x_float, z, y, 1, k, d(), l, verbose=false)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.\n\nCompute time (sec):     0.11840415000915527\nFinal loglikelihood:    -1441.522293255591\nIterations:             27\n\nSelected genetic predictors:\n15×2 DataFrame\n│ Row │ Position │ Estimated_β │\n│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n├─────┼──────────┼─────────────┤\n│ 1   │ 3464     │ -0.234958   │\n│ 2   │ 4383     │ -0.135693   │\n│ 3   │ 4927     │ 0.158171    │\n│ 4   │ 4938     │ -0.222613   │\n│ 5   │ 5001     │ -0.193739   │\n│ 6   │ 5011     │ -0.162718   │\n│ 7   │ 5018     │ -0.190532   │\n│ 8   │ 5090     │ 0.226509    │\n│ 9   │ 5092     │ -0.17756    │\n│ 10  │ 5100     │ -0.140337   │\n│ 11  │ 7004     │ 0.151748    │\n│ 12  │ 7011     │ 0.206449    │\n│ 13  │ 7015     │ -0.284706   │\n│ 14  │ 7016     │ 0.218126    │\n│ 15  │ 9902     │ 0.119059    │\n\nSelected nongenetic predictors:\n0×2 DataFrame","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"#run doubly sparse (group) IHT by specifying maximum number of SNPs for each group (in order)\nJ = 5\nmax_group_snps = ones(Int, num_blocks)\nmax_group_snps[true_groups] .= collect(1:5)\nvariable_group = L0_reg(x_float, z, y, J, max_group_snps, d(), l, verbose=false, group=g)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.\n\nCompute time (sec):     0.30719614028930664\nFinal loglikelihood:    -1446.3808810786898\nIterations:             16\n\nSelected genetic predictors:\n15×2 DataFrame\n│ Row │ Position │ Estimated_β │\n│     │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │\n├─────┼──────────┼─────────────┤\n│ 1   │ 3464     │ -0.245853   │\n│ 2   │ 4927     │ 0.160904    │\n│ 3   │ 4938     │ -0.213439   │\n│ 4   │ 5001     │ -0.19624    │\n│ 5   │ 5011     │ -0.149913   │\n│ 6   │ 5018     │ -0.181966   │\n│ 7   │ 5086     │ -0.0560478  │\n│ 8   │ 5090     │ 0.21164     │\n│ 9   │ 5092     │ -0.141968   │\n│ 10  │ 5100     │ -0.157655   │\n│ 11  │ 7004     │ 0.190224    │\n│ 12  │ 7011     │ 0.21294     │\n│ 13  │ 7015     │ -0.256058   │\n│ 14  │ 7016     │ 0.19746     │\n│ 15  │ 7020     │ 0.111755    │\n\nSelected nongenetic predictors:\n0×2 DataFrame","category":"page"},{"location":"man/examples/#Group-IHT-found-1-more-SNPs-than-ungrouped-IHT-1","page":"Examples","title":"Group IHT found 1 more SNPs than ungrouped IHT","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"#check result\ncorrect_position = findall(!iszero, true_b)\ncompare_model = DataFrame(\n    position = correct_position,\n    correct_β = true_b[correct_position],\n    ungrouped_IHT_β = ungrouped.beta[correct_position], \n    grouped_IHT_β = variable_group.beta[correct_position])\n@show compare_model\nprintln(\"\\n\")\n\n#clean up. Windows user must do this step manually (outside notebook/REPL)\nrm(\"tmp.bed\", force=true)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model = 15×4 DataFrame\n│ Row │ position │ correct_β │ ungrouped_IHT_β │ grouped_IHT_β │\n│     │ Int64    │ Float64   │ Float64         │ Float64       │\n├─────┼──────────┼───────────┼─────────────────┼───────────────┤\n│ 1   │ 3464     │ -0.2      │ -0.234958       │ -0.245853     │\n│ 2   │ 4927     │ 0.2       │ 0.158171        │ 0.160904      │\n│ 3   │ 4938     │ -0.2      │ -0.222613       │ -0.213439     │\n│ 4   │ 5001     │ -0.2      │ -0.193739       │ -0.19624      │\n│ 5   │ 5011     │ -0.2      │ -0.162718       │ -0.149913     │\n│ 6   │ 5018     │ -0.2      │ -0.190532       │ -0.181966     │\n│ 7   │ 5084     │ -0.2      │ 0.0             │ 0.0           │\n│ 8   │ 5090     │ 0.2       │ 0.226509        │ 0.21164       │\n│ 9   │ 5098     │ -0.2      │ 0.0             │ 0.0           │\n│ 10  │ 5100     │ -0.2      │ -0.140337       │ -0.157655     │\n│ 11  │ 7004     │ 0.2       │ 0.151748        │ 0.190224      │\n│ 12  │ 7011     │ 0.2       │ 0.206449        │ 0.21294       │\n│ 13  │ 7015     │ -0.2      │ -0.284706       │ -0.256058     │\n│ 14  │ 7016     │ 0.2       │ 0.218126        │ 0.19746       │\n│ 15  │ 7020     │ 0.2       │ 0.0             │ 0.111755      │","category":"page"},{"location":"man/examples/#Example-6:-Linear-Regression-with-prior-weights-1","page":"Examples","title":"Example 6: Linear Regression with prior weights","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"In this example, we show how to include (predetermined) prior weights for each SNP. You can check out our paper for references of why/how to choose these weights. In this case, we mimic our paper and randomly set 10 of all SNPs to have a weight of 20. Other predictors have weight of 10. All causal SNPs have weights of 20. Under this scenario, SNPs with weight 20 is twice as likely to enter the model identified by IHT. ","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"Our model is simulated as:","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"y_i sim mathbfx_i^Tmathbfbeta + epsilon_i","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"x_ij sim rm Binomial(2 rho_j)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"rho_j sim rm Uniform(0 05)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"epsilon_i sim rm N(0 1)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"beta_i sim rm N(0 1)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"#random seed\nRandom.seed!(4)\n\nd = Normal\nl = canonicallink(d())\nn = 1000\np = 10000\nk = 10\n\n# construct snpmatrix, covariate files, and true model b\nx = simulate_random_snparray(n, p, \"tmp.bed\")\nX = convert(Matrix{Float64}, x, center=true, scale=true)\nz = ones(n, 1) # the intercept\n    \n#define true_b \ntrue_b = zeros(p)\ntrue_b[1:10] .= collect(0.1:0.1:1.0)\nshuffle!(true_b)\ncorrect_position = findall(!iszero, true_b)\n\n#simulate phenotypes (e.g. vector y)\nprob = GLM.linkinv.(l, X * true_b)\nclamp!(prob, -20, 20)\ny = [rand(d(i)) for i in prob]\ny = Float64.(y);","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"# construct weight vector\nw = ones(p + 1)\nw[correct_position] .= 2.0\none_tenth = round(Int, p/10)\nidx = rand(1:p, one_tenth)\nw[idx] .= 2.0; #randomly set ~1/10 of all predictors to 2","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"#run IHT\nunweighted = L0_reg(X, z, y, 1, k, d(), l, verbose=false)\nweighted   = L0_reg(X, z, y, 1, k, d(), l, verbose=false, weight=w)\n\n#check result\ncompare_model = DataFrame(\n    position    = correct_position,\n    correct     = true_b[correct_position],\n    unweighted  = unweighted.beta[correct_position], \n    weighted    = weighted.beta[correct_position])\n@show compare_model\nprintln(\"\\n\")\n\n#clean up. Windows user must do this step manually (outside notebook/REPL)\nrm(\"tmp.bed\", force=true)","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"compare_model = 10×4 DataFrame\n│ Row │ position │ correct │ unweighted │ weighted │\n│     │ Int64    │ Float64 │ Float64    │ Float64  │\n├─────┼──────────┼─────────┼────────────┼──────────┤\n│ 1   │ 1254     │ 0.4     │ 0.452245   │ 0.450405 │\n│ 2   │ 1495     │ 0.3     │ 0.306081   │ 0.305738 │\n│ 3   │ 4856     │ 0.8     │ 0.853536   │ 0.862223 │\n│ 4   │ 5767     │ 0.1     │ 0.0        │ 0.117286 │\n│ 5   │ 5822     │ 0.7     │ 0.656213   │ 0.651908 │\n│ 6   │ 5945     │ 0.9     │ 0.891915   │ 0.894997 │\n│ 7   │ 6367     │ 0.5     │ 0.469718   │ 0.472524 │\n│ 8   │ 6996     │ 1.0     │ 0.963236   │ 0.973512 │\n│ 9   │ 7052     │ 0.6     │ 0.602162   │ 0.600055 │\n│ 10  │ 7980     │ 0.2     │ 0.231389   │ 0.234094 │","category":"page"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"In this case, weighted IHT found an extra predictor than non-weighted IHT.","category":"page"},{"location":"man/examples/#Other-examples-and-functionalities-1","page":"Examples","title":"Other examples and functionalities","text":"","category":"section"},{"location":"man/examples/#","page":"Examples","title":"Examples","text":"We explored a few more examples in our manuscript, with reproducible code. We invite users to experiment with them as well. ","category":"page"},{"location":"#Mendel-Iterative-Hard-Thresholding-1","page":"Home","title":"Mendel - Iterative Hard Thresholding","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"A modern approach to analyze data from a Genome Wide Association Studies (GWAS)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"note: Note\nPlease see the OpenMendel paper for a review of GWAS statistics and why we chose Julia as the programming language for this project. Pay attention to sections Handling SNP data and Iterative hard thresholding because they are especially relevant in this package.","category":"page"},{"location":"#Package-Feature-1","page":"Home","title":"Package Feature","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Analyze large GWAS datasets intuitively.\nBuilt-in parallel computing routines for q-fold cross-validation.\nFits a variety of generalized linear models with any choice of link function.\nComputation directly on raw genotype files.\nAbility to include non-genetic covariates.\nOptional acceleration (debias) step to dramatically improve speed.\nAbility to explicitly incorporate weights for predictors.\nAbility to enforce within and between group sparsity. \nNaive genotype imputation. \nEstimates nuisance parameter for negative binomial regression using Newton or MM algorithm. \nExcellent flexibility to handle different data structures and complements well with other Julia packages.","category":"page"},{"location":"#Manual-Outline-1","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\n    \"man/getting_started.md\",\n    \"man/examples.md\",\n    \"man/contributing.md\",\n]\nDepth = 2","category":"page"}]
}
