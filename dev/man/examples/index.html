<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Examples Â· MendelIHT</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">MendelIHT</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li class="is-active"><a class="tocitem" href>Examples</a><ul class="internal"><li><a class="tocitem" href="#Using-MendelIHT.jl"><span>Using MendelIHT.jl</span></a></li><li><a class="tocitem" href="#Example-1:-GWAS-with-PLINK-files"><span>Example 1: GWAS with PLINK files</span></a></li><li><a class="tocitem" href="#Example-2:-How-to-simulate-data"><span>Example 2: How to simulate data</span></a></li><li><a class="tocitem" href="#Example-3:-Logistic/Poisson/Negative-binomial-GWAS"><span>Example 3: Logistic/Poisson/Negative-binomial GWAS</span></a></li><li><a class="tocitem" href="#Example-4:-Running-IHT-on-general-matrices"><span>Example 4: Running IHT on general matrices</span></a></li><li><a class="tocitem" href="#Example-5:-Group-IHT"><span>Example 5: Group IHT</span></a></li><li><a class="tocitem" href="#Example-6:-Linear-Regression-with-prior-weights"><span>Example 6: Linear Regression with prior weights</span></a></li><li><a class="tocitem" href="#Other-examples-and-functionalities"><span>Other examples and functionalities</span></a></li></ul></li><li><a class="tocitem" href="../math/">Mathematical Details</a></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Examples</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Examples</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/OpenMendel/MendelIHT.jl/blob/master/docs/src/man/examples.md" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h1><p>Here we give numerous example analysis of GWAS data with <code>MendelIHT.jl</code>. </p><pre><code class="language-julia"># machine information for reproducibility
versioninfo()</code></pre><pre><code class="language-none">Julia Version 1.5.0
Commit 96786e22cc (2020-08-01 23:44 UTC)
Platform Info:
  OS: macOS (x86_64-apple-darwin18.7.0)
  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)</code></pre><pre><code class="language-julia"># add workers needed for parallel computing. Add only as many CPU cores available
using Distributed
addprocs(4)

#load necessary packages for running all examples below
@everywhere begin
    using Revise
    using MendelIHT
    using SnpArrays
    using DataFrames
    using Distributions
    using Random
    using LinearAlgebra
    using GLM
    using DelimitedFiles
    using Statistics
    using BenchmarkTools
end</code></pre><pre><code class="language-none">â”Œ Info: Precompiling MendelIHT [921c7187-1484-5754-b919-5d3ed9ac03c4]
â”” @ Base loading.jl:1278</code></pre><h2 id="Using-MendelIHT.jl"><a class="docs-heading-anchor" href="#Using-MendelIHT.jl">Using MendelIHT.jl</a><a id="Using-MendelIHT.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Using-MendelIHT.jl" title="Permalink"></a></h2><p>Users are exposed to 2 levels of interface:</p><ul><li>Wrapper functions <a href="https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.iht">iht()</a> and <a href="https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.cross_validate">cross_validate()</a>. These functions are simple scripts that import data, runs IHT, and writes result to output automatically. Since they are very simplistic, they might fail for whatever reason (please file an issue on GitHub). If so, please use:</li><li>Core functions <a href="https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.fit_iht">fit_iht()</a> and <a href="https://openmendel.github.io/MendelIHT.jl/latest/man/api/#MendelIHT.cv_iht">cv_iht()</a>. Input arguments for these functions must be first imported into Julia by the user manually.</li></ul><h2 id="Example-1:-GWAS-with-PLINK-files"><a class="docs-heading-anchor" href="#Example-1:-GWAS-with-PLINK-files">Example 1: GWAS with PLINK files</a><a id="Example-1:-GWAS-with-PLINK-files-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1:-GWAS-with-PLINK-files" title="Permalink"></a></h2><p>In this example, our data are stored in binary PLINK files:</p><ul><li><code>normal.bed</code></li><li><code>normal.bim</code></li><li><code>normal.fam</code></li></ul><p>which contains simulated (Gaussian) phenotypes for <span>$n=1000$</span> samples and <span>$p=10,000$</span> SNPs. There are <span>$8$</span> causal variants and 2 causal non-genetic covariates (intercept and sex). </p><p>These data are present under <code>MendelIHT/data</code> directory.</p><pre><code class="language-julia"># change directory to where example data is located
cd(normpath(MendelIHT.datadir()))

# show working directory
@show pwd() 

# show files in current directory
readdir()</code></pre><pre><code class="language-none">pwd() = &quot;/Users/biona001/.julia/dev/MendelIHT/data&quot;





12-element Array{String,1}:
 &quot;.DS_Store&quot;
 &quot;README.md&quot;
 &quot;covariates.txt&quot;
 &quot;cviht.summary.txt&quot;
 &quot;iht.beta.txt&quot;
 &quot;iht.summary.txt&quot;
 &quot;normal.bed&quot;
 &quot;normal.bim&quot;
 &quot;normal.fam&quot;
 &quot;normal_true_beta.txt&quot;
 &quot;phenotypes.txt&quot;
 &quot;simulate.jl&quot;</code></pre><p>Here <code>covariates.txt</code> contains non-genetic covariates, <code>normal.bed/bim/fam</code> are the PLINK files storing genetic covariates, <code>phenotypes.txt</code> are phenotypes for each sample, <code>normal_true_beta.txt</code> is the true statistical model used to generate the phenotypes, and <code>simulate.jl</code> is the script used to generate all the files. </p><h3 id="Step-1:-Run-cross-validation-to-determine-best-model-size"><a class="docs-heading-anchor" href="#Step-1:-Run-cross-validation-to-determine-best-model-size">Step 1: Run cross validation to determine best model size</a><a id="Step-1:-Run-cross-validation-to-determine-best-model-size-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Run-cross-validation-to-determine-best-model-size" title="Permalink"></a></h3><p>Here phenotypes are stored in the 6th column of <code>.fam</code> file. Other covariates are stored separately (which includes a column of 1 as intercept). Here we cross validate <span>$k = 1,2,...20$</span>. </p><pre><code class="language-julia">mses = cross_validate(&quot;normal&quot;, Normal, covariates=&quot;covariates.txt&quot;, phenotypes=6, path=1:20);

# Alternative syntax
# mses = cross_validate(&quot;normal&quot;, Normal, covariates=&quot;covariates.txt&quot;, phenotypes=6, path=[1, 5, 10, 15, 20]) # test k = 1, 5, 10, 15, 20
# mses = cross_validate(&quot;normal&quot;, Normal, covariates=&quot;covariates.txt&quot;, phenotypes=&quot;phenotypes.txt&quot;, path=1:20) # when phenotypes are stored separately</code></pre><pre><code class="language-none">[32mCross validating...100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:41[39m




Crossvalidation Results:
	k	MSE
	1	1406.4552580959744
	2	857.6790422237751
	3	675.7053829929064
	4	559.0287748247562
	5	424.84955802133055
	6	334.9624624153284
	7	304.97292908540294
	8	231.28136259326723
	9	197.38097683148538
	10	203.0158421015343
	11	205.5234762375722
	12	210.0832431714208
	13	208.30403888253082
	14	214.60823015711009
	15	215.379771415479
	16	229.2967482083606
	17	229.69491766374526
	18	234.89500599022892
	19	240.76951401560154
	20	242.39038987978827

Best k = 9</code></pre><p>Do not be alarmed if you get slightly different numbers, because cross validation breaks data into training/testing randomly. Set a seed by <code>Random.seed!(1234)</code> if you want reproducibility.</p><h3 id="Step-2:-Run-IHT-on-best-k"><a class="docs-heading-anchor" href="#Step-2:-Run-IHT-on-best-k">Step 2: Run IHT on best k</a><a id="Step-2:-Run-IHT-on-best-k-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Run-IHT-on-best-k" title="Permalink"></a></h3><p>According to cross validation, <code>k = 9</code> achieves the minimum MSE. Thus we run IHT on the full dataset.</p><pre><code class="language-julia">result = iht(&quot;normal&quot;, 9, Normal, covariates=&quot;covariates.txt&quot;, phenotypes=6);</code></pre><pre><code class="language-none">****                   MendelIHT Version 1.4.0                  ****
****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****
****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****
****                                                            ****
****                 Please cite our paper!                     ****
****         https://doi.org/10.1093/gigascience/giaa044        ****

Running sparse linear regression
Link functin = IdentityLink()
Sparsity parameter (k) = 9
Prior weight scaling = off
Doubly sparse projection = off
Debias = off
Max IHT iterations = 200
Converging when tol &lt; 0.0001:

Iteration 1: loglikelihood = -1407.0715526824579, backtracks = 0, tol = 0.7903070014734823
Iteration 2: loglikelihood = -1397.916093195947, backtracks = 0, tol = 0.025737058258134597
Iteration 3: loglikelihood = -1397.881115073396, backtracks = 0, tol = 0.0016722147159225114
Iteration 4: loglikelihood = -1397.8807458850451, backtracks = 0, tol = 0.0001440850615835579
Iteration 5: loglikelihood = -1397.8807416471927, backtracks = 0, tol = 1.674491317444967e-5
result = 
IHT estimated 7 nonzero SNP predictors and 2 non-genetic predictors.

Compute time (sec):     0.7361938953399658
Final loglikelihood:    -1397.8807416471927
SNP PVE:                0.834374956294435
Iterations:             5

Selected genetic predictors:
7Ã—2 DataFrame
 Row â”‚ Position  Estimated_Î²
     â”‚ Int64     Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚     3137     0.424377
   2 â”‚     4246     0.52343
   3 â”‚     4717     0.922857
   4 â”‚     6290    -0.677832
   5 â”‚     7755    -0.542981
   6 â”‚     8375    -0.792815
   7 â”‚     9415    -2.17998

Selected nongenetic predictors:
2Ã—2 DataFrame
 Row â”‚ Position  Estimated_Î²
     â”‚ Int64     Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚        1     1.65223
   2 â”‚        2     0.749866</code></pre><h3 id="Step-3:-Examine-results"><a class="docs-heading-anchor" href="#Step-3:-Examine-results">Step 3: Examine results</a><a id="Step-3:-Examine-results-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Examine-results" title="Permalink"></a></h3><p>IHT picked 7 SNPs and 2 non-genetic predictors: intercept and sex. The <code>Position</code> argument corresponds to the order in which the SNP appeared in the PLINK file, and the <code>Estimated_Î²</code> argument is the estimated effect size for the selected SNPs. To extract more information (for instance to extract <code>rs</code> IDs), we can do</p><pre><code class="language-julia">snpdata = SnpData(&quot;normal&quot;)                   # import PLINK information
snps_idx = findall(!iszero, result.beta)      # indices of SNPs selected by IHT
selected_snps = snpdata.snp_info[snps_idx, :] # see which SNPs are selected
@show selected_snps;</code></pre><pre><code class="language-none">selected_snps = 7Ã—6 DataFrame
 Row â”‚ chromosome  snpid    genetic_distance  position  allele1  allele2
     â”‚ String      String   Float64           Int64     String   String
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ 1           snp3137               0.0         1  1        2
   2 â”‚ 1           snp4246               0.0         1  1        2
   3 â”‚ 1           snp4717               0.0         1  1        2
   4 â”‚ 1           snp6290               0.0         1  1        2
   5 â”‚ 1           snp7755               0.0         1  1        2
   6 â”‚ 1           snp8375               0.0         1  1        2
   7 â”‚ 1           snp9415               0.0         1  1        2</code></pre><p>The table above displays the SNP information for the selected SNPs. </p><p>Since data is simulated, the fields <code>chromosome</code>, <code>snpid</code>, <code>genetic_distance</code>, <code>position</code>, <code>allele1</code>, and <code>allele2</code> are fake. </p><h2 id="Example-2:-How-to-simulate-data"><a class="docs-heading-anchor" href="#Example-2:-How-to-simulate-data">Example 2: How to simulate data</a><a id="Example-2:-How-to-simulate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2:-How-to-simulate-data" title="Permalink"></a></h2><p>Here we demonstrate how to use <code>MendelIHT.jl</code> and <a href="https://github.com/OpenMendel/SnpArrays.jl">SnpArrays.jl</a> to simulate data, allowing you to design your own genetic studies. Note:</p><ul><li>For more complex simulation, please use the module <a href="https://github.com/OpenMendel/TraitSimulation.jl">TraitSimulations.jl</a>.  </li><li>All linear algebra routines involving PLINK files are handled by <a href="https://github.com/OpenMendel/SnpArrays.jl">SnpArrays.jl</a>. </li></ul><p>First we simulate an example PLINK trio (<code>.bim</code>, <code>.bed</code>, <code>.fam</code>) and non-genetic covariates, then we illustrate how to import them. For simplicity, let us simulated indepent SNPs with binary phenotypes. Explicitly, our model is:</p><p class="math-container">\[y_i \sim \rm Bernoulli(\mathbf{x}_i^T\boldsymbol\beta)\]</p><p class="math-container">\[x_{ij} \sim \rm Binomial(2, \rho_j)\]</p><p class="math-container">\[\rho_j \sim \rm Uniform(0, 0.5)\]</p><p class="math-container">\[\beta_i \sim \rm N(0, 1)\]</p><p class="math-container">\[\beta_{\rm intercept} = 1\]</p><p class="math-container">\[\beta_{\rm sex} = 1.5\]</p><pre><code class="language-julia">n = 1000            # number of samples
p = 10000           # number of SNPs
k = 10              # 8 causal SNPs and 2 causal covariates (intercept + sex)
d = Bernoulli       # Binary (continuous) phenotypes
l = LogitLink()     # canonical link function

# set random seed
Random.seed!(1111)

# simulate `sim.bed` file with no missing data
x = simulate_random_snparray(&quot;sim.bed&quot;, n, p)
xla = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true, impute=true) 

# nongenetic covariate: first column is the intercept, second column is sex: 0 = male 1 = female
z = ones(n, 2) 
z[:, 2] .= rand(0:1, n)
standardize!(@view(z[:, 2:end])) 

# randomly set genetic predictors where causal Î²áµ¢ ~ N(0, 1)
true_b = zeros(p) 
true_b[1:k-2] = randn(k-2)
shuffle!(true_b)

# find correct position of genetic predictors
correct_position = findall(!iszero, true_b)

# define effect size of non-genetic predictors: intercept &amp; sex
true_c = [1.0; 1.5] 

# simulate phenotype using genetic and nongenetic predictors
prob = GLM.linkinv.(l, xla * true_b .+ z * true_c) # note genotype-vector multiplication is done with `xla`
y = [rand(d(i)) for i in prob]
y = Float64.(y); # turn y into floating point numbers

# create `sim.bim` and `sim.bam` files using phenotype
make_bim_fam_files(x, y, &quot;sim&quot;)

#save covariates and phenotypes (without header)
writedlm(&quot;sim.covariates.txt&quot;, z, &#39;,&#39;)
writedlm(&quot;sim.phenotypes.txt&quot;, y)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Please <strong>standardize</strong> (or at least center) your non-genetic covariates. If you use our <code>iht()</code> or <code>cross_validation()</code> functions, standardization is automatic. For genotype matrix, <code>SnpLinAlg</code> efficiently achieves this standardization. For non-genetic covariates, please use the built-in function <code>standardize!</code>. </p></div></div><h2 id="Example-3:-Logistic/Poisson/Negative-binomial-GWAS"><a class="docs-heading-anchor" href="#Example-3:-Logistic/Poisson/Negative-binomial-GWAS">Example 3: Logistic/Poisson/Negative-binomial GWAS</a><a id="Example-3:-Logistic/Poisson/Negative-binomial-GWAS-1"></a><a class="docs-heading-anchor-permalink" href="#Example-3:-Logistic/Poisson/Negative-binomial-GWAS" title="Permalink"></a></h2><p>In Example 2, we simulated binary phenotypes, genotypes, non-genetic covariates, and we know true <span>$k = 10$</span>. Let&#39;s try running a logistic regression (i.e. phenotype follows the Bernoulli distribution) on this data. </p><pre><code class="language-julia">result = iht(&quot;sim&quot;, 10, Bernoulli, covariates=&quot;sim.covariates.txt&quot;);</code></pre><pre><code class="language-none">****                   MendelIHT Version 1.4.0                  ****
****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****
****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****
****                                                            ****
****                 Please cite our paper!                     ****
****         https://doi.org/10.1093/gigascience/giaa044        ****

Running sparse logistic regression
Link functin = LogitLink()
Sparsity parameter (k) = 10
Prior weight scaling = off
Doubly sparse projection = off
Debias = off
Max IHT iterations = 200
Converging when tol &lt; 0.0001:

Iteration 1: loglikelihood = -403.91876912829684, backtracks = 0, tol = 0.5882274462947444
Iteration 2: loglikelihood = -354.24157363893784, backtracks = 0, tol = 0.282513866845802
Iteration 3: loglikelihood = -347.5483388154264, backtracks = 0, tol = 0.19289827584644761
Iteration 4: loglikelihood = -335.9715247464944, backtracks = 0, tol = 0.1426996228393492
Iteration 5: loglikelihood = -334.49756712078744, backtracks = 1, tol = 0.02283147714926763
Iteration 6: loglikelihood = -333.543219571108, backtracks = 2, tol = 0.019792429262652955
Iteration 7: loglikelihood = -332.8067268854347, backtracks = 2, tol = 0.019845664939460095
Iteration 8: loglikelihood = -332.5588563458224, backtracks = 3, tol = 0.00765066824120313
Iteration 9: loglikelihood = -332.3619297572997, backtracks = 3, tol = 0.006913691748350025
Iteration 10: loglikelihood = -332.2064289061609, backtracks = 3, tol = 0.0061597575486623014
Iteration 11: loglikelihood = -332.0840431892422, backtracks = 3, tol = 0.0054730856932040705
Iteration 12: loglikelihood = -331.98800416752806, backtracks = 3, tol = 0.0048548461339783565
Iteration 13: loglikelihood = -331.9128408595039, backtracks = 3, tol = 0.004300010671833966
Iteration 14: loglikelihood = -331.85415737528945, backtracks = 3, tol = 0.0038033387186573
Iteration 15: loglikelihood = -331.8084401845103, backtracks = 3, tol = 0.003359795402130408
Iteration 16: loglikelihood = -331.77289417483837, backtracks = 3, tol = 0.0029645876127234955
Iteration 17: loglikelihood = -331.74530513071767, backtracks = 3, tol = 0.0026131815201996976
Iteration 18: loglikelihood = -331.72392566719304, backtracks = 3, tol = 0.002301318021364227
Iteration 19: loglikelihood = -331.707381516887, backtracks = 3, tol = 0.002025024729429744
Iteration 20: loglikelihood = -331.6945951739729, backtracks = 3, tol = 0.001780622915677454
Iteration 21: loglikelihood = -331.6847241325898, backtracks = 3, tol = 0.0015647287330161268
Iteration 22: loglikelihood = -331.6771112518333, backtracks = 3, tol = 0.0013742489121423226
Iteration 23: loglikelihood = -331.671245094309, backtracks = 3, tol = 0.0012063716814260336
Iteration 24: loglikelihood = -331.6667283950377, backtracks = 3, tol = 0.0010585539268262742
Iteration 25: loglikelihood = -331.66325310683357, backtracks = 3, tol = 0.0009285056582307361
Iteration 26: loglikelihood = -331.66058072924545, backtracks = 3, tol = 0.0008141727680124563
Iteration 27: loglikelihood = -331.6585268570943, backtracks = 3, tol = 0.0007137189219975595
Iteration 28: loglikelihood = -331.6569490812431, backtracks = 3, tol = 0.0006255072563945025
Iteration 29: loglikelihood = -331.65573754039684, backtracks = 3, tol = 0.0005480823925167159
Iteration 30: loglikelihood = -331.6548075608974, backtracks = 3, tol = 0.00048015313770763916
Iteration 31: loglikelihood = -331.65409393532707, backtracks = 3, tol = 0.0004205761209236388
Iteration 32: loglikelihood = -331.6535464833441, backtracks = 3, tol = 0.00036834051544793833
Iteration 33: loglikelihood = -331.6531266130592, backtracks = 3, tol = 0.00032255392716466075
Iteration 34: loglikelihood = -331.6528046612902, backtracks = 3, tol = 0.00028242947163362354
Iteration 35: loglikelihood = -331.65255783889444, backtracks = 3, tol = 0.0002472740235281775
Iteration 36: loglikelihood = -331.6523686452689, backtracks = 3, tol = 0.00021647759466681234
Iteration 37: loglikelihood = -331.652223646102, backtracks = 3, tol = 0.00018950377910949886
Iteration 38: loglikelihood = -331.6521125319518, backtracks = 3, tol = 0.00016588119325870545
Iteration 39: loglikelihood = -331.6520273936599, backtracks = 3, tol = 0.00014519583372057257
Iteration 40: loglikelihood = -331.65196216503995, backtracks = 3, tol = 0.0001270842743388486
Iteration 41: loglikelihood = -331.65191219446064, backtracks = 3, tol = 0.00011122762514495094
Iteration 42: loglikelihood = -331.6518739156732, backtracks = 3, tol = 9.734617909701182e-5
result = 
IHT estimated 8 nonzero SNP predictors and 2 non-genetic predictors.

Compute time (sec):     4.042757987976074
Final loglikelihood:    -331.6518739156732
SNP PVE:                0.4798854810844273
Iterations:             42

Selected genetic predictors:
8Ã—2 DataFrame
 Row â”‚ Position  Estimated_Î²
     â”‚ Int64     Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚     3137     0.503252
   2 â”‚     4246     0.590809
   3 â”‚     4248    -0.37987
   4 â”‚     4717     1.04006
   5 â”‚     6290    -0.741734
   6 â”‚     7755    -0.437585
   7 â”‚     8375    -0.942293
   8 â”‚     9415    -2.11206

Selected nongenetic predictors:
2Ã—2 DataFrame
 Row â”‚ Position  Estimated_Î²
     â”‚ Int64     Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚        1      1.03892
   2 â”‚        2      1.5844</code></pre><p>Since data is simulated, we can compare IHT&#39;s estimated effect size with the truth. </p><pre><code class="language-julia">[true_b[correct_position] result.beta[correct_position]]</code></pre><pre><code class="language-none">8Ã—2 Array{Float64,2}:
  0.469278    0.503252
  0.554408    0.590809
  0.923213    1.04006
  0.0369732   0.0
 -0.625634   -0.741734
 -0.526553   -0.437585
 -0.815561   -0.942293
 -2.18271    -2.11206</code></pre><p>The 1st column are the true beta values, and the 2nd column is the estimated values. IHT found 7/8 genetic predictors, and estimates are reasonably close to truth. IHT missed one SNP with very small effect size (<span>$\beta = 0.0369$</span>). The estimated non-genetic effect size is also very close to the truth (1.0 and 1.5). </p><pre><code class="language-julia"># remove simulated data once they are no longer needed
rm(&quot;sim.bed&quot;, force=true)
rm(&quot;sim.bim&quot;, force=true)
rm(&quot;sim.fam&quot;, force=true)
rm(&quot;sim.covariates.txt&quot;, force=true)
rm(&quot;sim.phenotypes.txt&quot;, force=true)
rm(&quot;iht.beta.txt&quot;, force=true)
rm(&quot;iht.summary.txt&quot;, force=true)
rm(&quot;cviht.summary.txt&quot;, force=true)</code></pre><h2 id="Example-4:-Running-IHT-on-general-matrices"><a class="docs-heading-anchor" href="#Example-4:-Running-IHT-on-general-matrices">Example 4: Running IHT on general matrices</a><a id="Example-4:-Running-IHT-on-general-matrices-1"></a><a class="docs-heading-anchor-permalink" href="#Example-4:-Running-IHT-on-general-matrices" title="Permalink"></a></h2><p>To run IHT on genotypes in VCF files, or other general data, one must call <code>fit_iht</code> and <code>cv_iht</code> directly. These functions are designed to work on <code>AbstractArray{T, 2}</code> type where <code>T</code> is a <code>Float64</code> or <code>Float32</code>. Thus, one must first import the data, and then call <code>fit_iht</code> and <code>cv_iht</code> on it. Note the vector of 1s (intercept) shouldn&#39;t be included in the design matrix itself, as it will be automatically included.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>Check out <a href="https://github.com/OpenMendel/VCFTools.jl">VCFTools.jl</a> to learn how to import VCF data.</p></div></div><p>First we simulate some count response using the model:</p><p class="math-container">\[y_i \sim \rm Poisson(\mathbf{x}_i^T \boldsymbol\beta)\]</p><p class="math-container">\[x_{ij} \sim \rm Normal(0, 1)\]</p><p class="math-container">\[\beta_i \sim \rm N(0, 0.3)\]</p><pre><code class="language-julia">n = 1000             # number of samples
p = 10000            # number of SNPs
k = 10               # 9 causal predictors + intercept
d = Poisson          # Response follows Poisson distribution (count data)
l = LogLink()        # canonical link

# set random seed for reproducibility
Random.seed!(2020)

# simulate design matrix
x = randn(n, p)

# simulate response, true model b, and the correct non-0 positions of b
true_b = zeros(p)
true_b[1:k] .= rand(Normal(0, 0.5), k)
shuffle!(true_b)
intercept = 1.0
correct_position = findall(!iszero, true_b)
prob = GLM.linkinv.(l, intercept .+ x * true_b)
clamp!(prob, -20, 20) # prevents overflow
y = [rand(d(i)) for i in prob]
y = Float64.(y); # convert phenotypes to double precision</code></pre><p>Now we have the response <span>$y$</span>, design matrix <span>$x$</span>. Let&#39;s run IHT and compare with truth.</p><pre><code class="language-julia"># first run cross validation 
mses = cv_iht(y, x, path=1:20, d=Poisson(), l=LogLink());</code></pre><pre><code class="language-none">[32mCross validating...100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:13[39m




Crossvalidation Results:
	k	MSE
	1	1489.8188363695676
	2	707.6175237350031
	3	546.8867981545659
	4	467.2192708681082
	5	440.03761893872735
	6	459.9446241516855
	7	482.3184687223138
	8	504.0229684333779
	9	495.12633308066677
	10	525.4353275609003
	11	534.0267905856207
	12	524.761614819788
	13	558.2726852255062
	14	561.6025100531801
	15	561.3898895087017
	16	555.5897051455378
	17	618.3872529214121
	18	655.395210924614
	19	652.4915677346956
	20	561.4237250226572

Best k = 5</code></pre><p>Now run IHT on the full dataset using the best k (achieved at k = 5)</p><pre><code class="language-julia">result = fit_iht(y, x, k=argmin(mses), d=Poisson(), l=LogLink())</code></pre><pre><code class="language-none">****                   MendelIHT Version 1.4.0                  ****
****     Benjamin Chu, Kevin Keys, Chris German, Hua Zhou       ****
****   Jin Zhou, Eric Sobel, Janet Sinsheimer, Kenneth Lange    ****
****                                                            ****
****                 Please cite our paper!                     ****
****         https://doi.org/10.1093/gigascience/giaa044        ****

Running sparse Poisson regression
Link functin = LogLink()
Sparsity parameter (k) = 5
Prior weight scaling = off
Doubly sparse projection = off
Debias = off
Max IHT iterations = 200
Converging when tol &lt; 0.0001:

Iteration 1: loglikelihood = -2847.082501924986, backtracks = 0, tol = 0.2928574304111579
Iteration 2: loglikelihood = -2465.401434829009, backtracks = 0, tol = 0.05230999409875657
Iteration 3: loglikelihood = -2376.6519599956155, backtracks = 0, tol = 0.07104164424891486
Iteration 4: loglikelihood = -2351.5833133504116, backtracks = 0, tol = 0.026208176849564724
Iteration 5: loglikelihood = -2343.11078282251, backtracks = 0, tol = 0.02023001613423483
Iteration 6: loglikelihood = -2339.0692529047387, backtracks = 0, tol = 0.011080308351803736
Iteration 7: loglikelihood = -2337.149479249759, backtracks = 0, tol = 0.00930914236578197
Iteration 8: loglikelihood = -2336.1781402958745, backtracks = 0, tol = 0.00556416943618412
Iteration 9: loglikelihood = -2335.6908426969235, backtracks = 0, tol = 0.004609772037770406
Iteration 10: loglikelihood = -2335.440388139586, backtracks = 0, tol = 0.002861799512474864
Iteration 11: loglikelihood = -2335.3124548737906, backtracks = 0, tol = 0.002340881298705853
Iteration 12: loglikelihood = -2335.2463824561282, backtracks = 0, tol = 0.001479832987797599
Iteration 13: loglikelihood = -2335.2123851939327, backtracks = 0, tol = 0.0012011066579049358
Iteration 14: loglikelihood = -2335.1947979604856, backtracks = 0, tol = 0.0007661746047595665
Iteration 15: loglikelihood = -2335.1857186752313, backtracks = 0, tol = 0.0006191995770663082
Iteration 16: loglikelihood = -2335.1810189052294, backtracks = 0, tol = 0.00039678836835178535
Iteration 17: loglikelihood = -2335.178588840017, backtracks = 0, tol = 0.00031993814923964465
Iteration 18: loglikelihood = -2335.177330620363, backtracks = 0, tol = 0.00020549845888243352
Iteration 19: loglikelihood = -2335.1766795324024, backtracks = 0, tol = 0.00016549800033345948
Iteration 20: loglikelihood = -2335.176342377269, backtracks = 0, tol = 0.00010642830220001078
Iteration 21: loglikelihood = -2335.176167840737, backtracks = 0, tol = 8.565816720868677e-5






IHT estimated 4 nonzero SNP predictors and 1 non-genetic predictors.

Compute time (sec):     0.12793207168579102
Final loglikelihood:    -2335.176167840737
SNP PVE:                0.09113449276174615
Iterations:             21

Selected genetic predictors:
[1m4Ã—2 DataFrame[0m
[1m Row [0mâ”‚[1m Position [0m[1m Estimated_Î² [0m
[1m     [0mâ”‚[90m Int64    [0m[90m Float64     [0m
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚       83    -0.809284
   2 â”‚      989     0.378376
   3 â”‚     4294    -0.274544
   4 â”‚     4459     0.169417

Selected nongenetic predictors:
[1m1Ã—2 DataFrame[0m
[1m Row [0mâ”‚[1m Position [0m[1m Estimated_Î² [0m
[1m     [0mâ”‚[90m Int64    [0m[90m Float64     [0m
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚        1      1.26918</code></pre><pre><code class="language-julia"># compare IHT result with truth
[true_b[correct_position] result.beta[correct_position]]</code></pre><pre><code class="language-none">10Ã—2 Array{Float64,2}:
 -1.303      -0.809284
  0.585809    0.378376
 -0.0700563   0.0
 -0.0901341   0.0
 -0.0620201   0.0
 -0.441452   -0.274544
  0.271429    0.169417
 -0.164888    0.0
 -0.0790484   0.0
  0.0829054   0.0</code></pre><p>Since many of the true <span>$\beta$</span> are small, we were only able to find 5 true signals (4 predictors + intercept). </p><p><strong>Conclusion:</strong> In this example, we ran IHT on count response with a general <code>Array{T, 2}</code> design matrix. Since we used simulated data, we could compare IHT&#39;s estimates with the truth. </p><h2 id="Example-5:-Group-IHT"><a class="docs-heading-anchor" href="#Example-5:-Group-IHT">Example 5: Group IHT</a><a id="Example-5:-Group-IHT-1"></a><a class="docs-heading-anchor-permalink" href="#Example-5:-Group-IHT" title="Permalink"></a></h2><p>In this example, we show how to include group information to perform doubly sparse projections. Here the final model would contain at most <span>$J = 5$</span> groups where each group contains limited number of (prespecified) SNPs. For simplicity, we assume the sparsity parameter <span>$k$</span> is known. </p><h3 id="Data-simulation"><a class="docs-heading-anchor" href="#Data-simulation">Data simulation</a><a id="Data-simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Data-simulation" title="Permalink"></a></h3><p>To illustrate the effect of group information and prior weights, we generated correlated genotype matrix according to the procedure outlined in <a href="https://www.biorxiv.org/content/biorxiv/early/2019/11/19/697755.full.pdf">our paper</a>. In this example, each SNP belongs to 1 of 500 disjoint groups containing 20 SNPs each; <span>$j = 5$</span> distinct groups are each assigned <span>$1,2,...,5$</span> causal SNPs with effect sizes randomly chosen from <span>$\{âˆ’0.2,0.2\}$</span>. In all there 15 causal SNPs.  For grouped-IHT, we assume perfect group information. That is, the selected groups containing 1âˆ¼5 causative SNPs are assigned maximum within-group sparsity <span>$\lambda_g = 1,2,...,5$</span>. The remaining groups are assigned <span>$\lambda_g = 1$</span> (i.e. only 1 active predictor are allowed).</p><pre><code class="language-julia"># define problem size
d = NegativeBinomial
l = LogLink()
n = 1000
p = 10000
block_size = 20                  #simulation parameter
num_blocks = Int(p / block_size) #simulation parameter

# set seed
Random.seed!(2019)

# assign group membership
membership = collect(1:num_blocks)
g = zeros(Int64, p + 1)
for i in 1:length(membership)
    for j in 1:block_size
        cur_row = block_size * (i - 1) + j
        g[block_size*(i - 1) + j] = membership[i]
    end
end
g[end] = membership[end]

#simulate correlated snparray
x = simulate_correlated_snparray(&quot;tmp.bed&quot;, n, p)
intercept = 0.5
x_float = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, center=true, scale=true)

#simulate true model, where 5 groups each with 1~5 snps contribute
true_b = zeros(p)
true_groups = randperm(num_blocks)[1:5]
sort!(true_groups)
within_group = [randperm(block_size)[1:1], randperm(block_size)[1:2], 
                randperm(block_size)[1:3], randperm(block_size)[1:4], 
                randperm(block_size)[1:5]]
correct_position = zeros(Int64, 15)
for i in 1:5
    cur_group = block_size * (true_groups[i] - 1)
    cur_group_snps = cur_group .+ within_group[i]
    start, last = Int(i*(i-1)/2 + 1), Int(i*(i+1)/2)
    correct_position[start:last] .= cur_group_snps
end
for i in 1:15
    true_b[correct_position[i]] = rand(-1:2:1) * 0.2
end
sort!(correct_position)

# simulate phenotype
r = 10 #nuisance parameter
Î¼ = GLM.linkinv.(l, intercept .+ x_float * true_b)
clamp!(Î¼, -20, 20)
prob = 1 ./ (1 .+ Î¼ ./ r)
y = [rand(d(r, i)) for i in prob] #number of failures before r success occurs
y = Float64.(y);</code></pre><pre><code class="language-julia">#run IHT without groups
ungrouped = fit_iht(y, x_float, k=15, d=NegativeBinomial(), l=LogLink(), verbose=false)

#run doubly sparse (group) IHT by specifying maximum number of SNPs for each group (in order)
max_group_snps = ones(Int, num_blocks)
max_group_snps[true_groups] .= collect(1:5)
variable_group = fit_iht(y, x_float, d=NegativeBinomial(), l=LogLink(), k=max_group_snps, J=5, group=g, verbose=false);</code></pre><pre><code class="language-julia">#check result
correct_position = findall(!iszero, true_b)
compare_model = DataFrame(
    position = correct_position,
    correct_Î² = true_b[correct_position],
    ungrouped_IHT_Î² = ungrouped.beta[correct_position], 
    grouped_IHT_Î² = variable_group.beta[correct_position])
@show compare_model
println(&quot;\n&quot;)

#clean up. Windows user must do this step manually (outside notebook/REPL)
rm(&quot;tmp.bed&quot;, force=true)</code></pre><pre><code class="language-none">compare_model = 15Ã—4 DataFrame
 Row â”‚ position  correct_Î²  ungrouped_IHT_Î²  grouped_IHT_Î²
     â”‚ Int64     Float64    Float64          Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚      235       -0.2        -0.218172       0.0
   2 â”‚     2673       -0.2        -0.171002      -0.178483
   3 â”‚     2679       -0.2        -0.236793      -0.213098
   4 â”‚     6383       -0.2        -0.228555      -0.224309
   5 â”‚     6389       -0.2        -0.190352      -0.192022
   6 â”‚     6394        0.2         0.215984       0.198447
   7 â”‚     7862        0.2         0.229254       0.224207
   8 â”‚     7864       -0.2        -0.184551      -0.19331
   9 â”‚     7868       -0.2        -0.174773      -0.177359
  10 â”‚     7870       -0.2        -0.192932      -0.208592
  11 â”‚     9481       -0.2         0.0            0.0
  12 â”‚     9491        0.2         0.0            0.0
  13 â”‚     9493        0.2         0.183659       0.175211
  14 â”‚     9494        0.2         0.117548       0.112946
  15 â”‚     9499       -0.2         0.0            0.0</code></pre><p><strong>Conclusion:</strong> Ungroup IHT actually found 1 more SNPs than grouped IHT. </p><h2 id="Example-6:-Linear-Regression-with-prior-weights"><a class="docs-heading-anchor" href="#Example-6:-Linear-Regression-with-prior-weights">Example 6: Linear Regression with prior weights</a><a id="Example-6:-Linear-Regression-with-prior-weights-1"></a><a class="docs-heading-anchor-permalink" href="#Example-6:-Linear-Regression-with-prior-weights" title="Permalink"></a></h2><p>In this example, we show how to include (predetermined) prior weights for each SNP. You can check out <a href="https://www.biorxiv.org/content/biorxiv/early/2019/11/19/697755.full.pdf">our paper</a> for references of why/how to choose these weights. In this case, we mimic our paper and randomly set <span>$10\%$</span> of all SNPs to have a weight of <span>$2.0$</span>. Other predictors have weight of <span>$1.0$</span>. All causal SNPs have weights of <span>$2.0$</span>. Under this scenario, SNPs with weight <span>$2.0$</span> is twice as likely to enter the model identified by IHT. </p><p>Our model is simulated as:</p><p class="math-container">\[y_i \sim \mathbf{x}_i^T\mathbf{\beta} + \epsilon_i\]</p><p class="math-container">\[x_{ij} \sim \rm Binomial(2, \rho_j)\]</p><p class="math-container">\[\rho_j \sim \rm Uniform(0, 0.5)\]</p><p class="math-container">\[\epsilon_i \sim \rm N(0, 1)\]</p><p class="math-container">\[\beta_i \sim \rm N(0, 0.25)\]</p><pre><code class="language-julia">d = Normal
l = IdentityLink()
n = 1000
p = 10000
k = 10

#random seed
Random.seed!(4)

# construct snpmatrix, covariate files, and true model b
x = simulate_random_snparray(&quot;tmp.bed&quot;, n, p)
X = convert(Matrix{Float64}, x, center=true, scale=true)
intercept = 1.0
    
#define true_b 
true_b = zeros(p)
true_b[1:10] .= rand(Normal(0, 0.25), k)
shuffle!(true_b)
correct_position = findall(!iszero, true_b)

#simulate phenotypes (e.g. vector y)
prob = GLM.linkinv.(l, intercept .+ X * true_b)
clamp!(prob, -20, 20)
y = [rand(d(i)) for i in prob]
y = Float64.(y);

# construct weight vector
w = ones(p + 1)
w[correct_position] .= 2.0
one_tenth = round(Int, p/10)
idx = rand(1:p, one_tenth)
w[idx] .= 2.0; #randomly set ~1/10 of all predictors to 2</code></pre><pre><code class="language-julia">#run weighted and unweighted IHT
unweighted = fit_iht(y, X, k=10, d=Normal(), l=IdentityLink(), verbose=false)
weighted   = fit_iht(y, X, k=10, d=Normal(), l=IdentityLink(), verbose=false, weight=w)

#check result
compare_model = DataFrame(
    position    = correct_position,
    correct     = true_b[correct_position],
    unweighted  = unweighted.beta[correct_position], 
    weighted    = weighted.beta[correct_position])
@show compare_model
println(&quot;\n&quot;)

#clean up. Windows user must do this step manually (outside notebook/REPL)
rm(&quot;tmp.bed&quot;, force=true)</code></pre><pre><code class="language-none">compare_model = 10Ã—4 DataFrame
 Row â”‚ position  correct     unweighted  weighted
     â”‚ Int64     Float64     Float64     Float64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚     1264   0.252886     0.270233   0.264713
   2 â”‚     1506  -0.0939841    0.0       -0.125803
   3 â”‚     4866  -0.227394    -0.233703  -0.237007
   4 â”‚     5778  -0.510488    -0.507114  -0.494199
   5 â”‚     5833  -0.311969    -0.324309  -0.322663
   6 â”‚     5956  -0.0548168    0.0        0.0
   7 â”‚     6378  -0.0155173    0.0        0.0
   8 â”‚     7007  -0.123301     0.0        0.0
   9 â”‚     7063   0.0183886    0.0        0.0
  10 â”‚     7995  -0.102122     0.0       -0.142201</code></pre><p><strong>Conclusion</strong>: weighted IHT found 2 extra predictor than non-weighted IHT.</p><h2 id="Other-examples-and-functionalities"><a class="docs-heading-anchor" href="#Other-examples-and-functionalities">Other examples and functionalities</a><a id="Other-examples-and-functionalities-1"></a><a class="docs-heading-anchor-permalink" href="#Other-examples-and-functionalities" title="Permalink"></a></h2><p>Additional features are available as optional parameters in the <a href="https://github.com/OpenMendel/MendelIHT.jl/blob/master/src/fit.jl#L37">fit_iht</a> function, but they should be treated as <strong>experimental</strong> features. Interested users are encouraged to explore them and please file issues on GitHub if you encounter a problem.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../getting_started/">Â« Getting Started</a><a class="docs-footer-nextpage" href="../math/">Mathematical Details Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 18 April 2021 03:34">Sunday 18 April 2021</span>. Using Julia version 1.5.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
